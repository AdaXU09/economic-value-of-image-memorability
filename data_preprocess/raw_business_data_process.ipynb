{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e36bf0",
   "metadata": {},
   "source": [
    "# business 跑模型数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1227510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据格式的转换\n",
    "\n",
    "def protect_excel_formula(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: f\"'{x}\" if isinstance(x, str) and x.startswith(('=', '+', '-', '@')) else x\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "def json_to_excel(json_path,excel_path):\n",
    "    \"\"\"\n",
    "    json_path:input read file json path\n",
    "    excel_path:output write file excel path\n",
    "    return:None\n",
    "    \"\"\"\n",
    "    data_excel = []\n",
    "    with open(json_path, 'r', encoding='utf-8') as json_file:\n",
    "        all = json_file.readlines()\n",
    "        header = list(json.loads(all[0]).keys())\n",
    "        for line in all:\n",
    "            data =  list(json.loads(line).values())\n",
    "            data_excel.append(data)\n",
    "    df = pd.DataFrame(data_excel,columns=header)\n",
    "    dfs = protect_excel_formula(df)\n",
    "    dfs.to_excel(excel_path,index=False)\n",
    "    print(\"{} data save success\".format(json_path))\n",
    "\n",
    "\n",
    "def json_to_csv(json_path,excel_path):\n",
    "    \"\"\"\n",
    "    json_path:input read file json path\n",
    "    excel_path:output write file excel path\n",
    "    return:None\n",
    "    \"\"\"\n",
    "    data_excel = []\n",
    "    with open(json_path, 'r', encoding='utf-8') as json_file:\n",
    "        all = json_file.readlines()\n",
    "        header = list(json.loads(all[0]).keys())\n",
    "        for line in all:\n",
    "            data =  list(json.loads(line).values())\n",
    "            data_excel.append(data)\n",
    "    df = pd.DataFrame(data_excel,columns=header)\n",
    "    dfs = protect_excel_formula(df)\n",
    "    dfs.to_csv(excel_path,index=False)\n",
    "    print(\"{} data save success\".format(json_path))\n",
    "\n",
    "\n",
    "\n",
    "file_names = os.listdir('./data/json')\n",
    "for file_name in file_names[3:]:\n",
    "    print(file_name)\n",
    "    try:\n",
    "        input_path = './data/json/'+file_name\n",
    "        ouput_put = './data/excel/'+file_name.replace(\"json\",'xlsx')\n",
    "        json_to_excel(input_path,ouput_put)\n",
    "    except:\n",
    "        ouput_put = './data/excel/'+file_name.replace(\"json\",'csv')\n",
    "        json_to_csv(input_path,ouput_put)\n",
    "# 参数1 输入路径json 参数2 输出路径\n",
    "# json_to_csv(\"***.json\",\"***.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd40257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------tips-----------------------------------------------\n",
    "# tips data ==> generate summary data  对tips数据集进行分组统计，分组条件business_id\n",
    "# df = pd.read_csv('./data/excel/yelp_academic_dataset_tip.csv')\n",
    "# result = df.groupby('business_id').agg({'user_id':len,\n",
    "#                         'compliment_count': [np.average,np.std],\n",
    "#                         }).reset_index().values.tolist()\n",
    "# pd.DataFrame(result, columns = ['business_id','tips_count','compliment_avg','compliment_std'\n",
    "#                                 ]).to_csv('./data/excel/tips_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f12f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------review-----------------------------------------------\n",
    "# from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# # content_score 计算评论情感的分数\n",
    "# def analyze_sentiment(sentence):\n",
    "#     sid = SentimentIntensityAnalyzer()\n",
    "#     sentiment_scores = sid.polarity_scores(sentence)\n",
    "#     return sentiment_scores['compound']\n",
    "\n",
    "# 遍历数据集并保存评分结果\n",
    "# # calculate review text score\n",
    "# # df = pd.read_csv('./data/excel/yelp_academic_dataset_review.csv')\n",
    "# df = pd.read_csv('review_new.csv')\n",
    "# result = []\n",
    "# for index,row in df.iterrows():\n",
    "#     print(index,analyze_sentiment(row['text']))\n",
    "#     result.append([index,analyze_sentiment(row['text'])])\n",
    "# pd.DataFrame(result,columns=['index','score']).to_csv('./data/excel/review_score_result_1_new.csv',index=False)\n",
    "\n",
    "# # 合并 review与情感评分数据\n",
    "df = pd.read_csv('./data/excel/yelp_academic_dataset_review.csv')\n",
    "df = df[['user_id', 'business_id', 'stars', 'useful', 'funny','cool']]\n",
    "dfs = pd.read_csv('./data/excel/review_score_result_1.csv')\n",
    "df = pd.concat([df,dfs],axis=1)\n",
    "df = df[['user_id', 'business_id', 'stars', 'useful', 'funny','cool','score']]\n",
    "df.to_csv('./data/excel/review_merge.csv',index=False)\n",
    "\n",
    "\n",
    "# 对合并好的数据进行分组summary 统计\n",
    "df = pd.read_csv('./data/excel/review_merge.csv')\n",
    "result = df.groupby('business_id').agg({'user_id':pd.Series.nunique,\n",
    "                        'stars': [np.average, np.std],\n",
    "                        'score': [np.average], \n",
    "                        'useful': [np.average], \n",
    "                        'funny': [np.average],\n",
    "                        'cool': [np.average], \n",
    "                        }).reset_index().values.tolist()\n",
    "pd.DataFrame(result, columns = ['business_id','user_count','star_avg','star_std','contents_score_avg',\n",
    "                                'useful_avg','funny_avg','cool_avg',]).to_csv('./data/excel/review_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f44c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------photo-----------------------------------------------\n",
    "# 基于图片计算 memory_score h s v\n",
    "import cv2\n",
    "import os\n",
    "from resmem import ResMem, transformer\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# memory_score\n",
    "model = ResMem(pretrained=True)\n",
    "def pic_score_pre(pic_path):\n",
    "    img = Image.open(pic_path) # This loads your image into memory\n",
    "    img = img.convert('RGB') \n",
    "    # This will convert your image into RGB, for instance if it's a PNG (RGBA) or if it's black and white.\n",
    "    model.eval()\n",
    "    # Set the model to inference mode.\n",
    "    image_x = transformer(img)\n",
    "    # Run the preprocessing function\n",
    "    # print(image_x.shape)\n",
    "    prediction = model(image_x.view(-1, 3, 227, 227))\n",
    "    # For a single image, the image must be reshaped into a batch\n",
    "    # with size 1.\n",
    "    # Get your prediction!\n",
    "    return round(prediction[0][0].item(),3)\n",
    "\n",
    "\n",
    "\n",
    "def get_hsv(pic_path):\n",
    "    # read pic\n",
    "    img = cv2.imread(pic_path)\n",
    "\n",
    "    # transform hsv color\n",
    "    hsv_img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # get h s v \n",
    "    h,s,v = cv2.split(hsv_img)\n",
    "\n",
    "    # print(h, s, v)\n",
    "    # print(np.mean(h),np.mean(s),np.mean(v))\n",
    "\n",
    "    return round(np.mean(h),3),round(np.mean(s),3),round(np.mean(v),3)\n",
    "\n",
    "# def pic_detail_to_summary(detail_file,output_path):\n",
    "#     file = pd.read_excel(detail_file)\n",
    "\n",
    "\n",
    "fs = open('./data/log/pic.log','w+',encoding='utf-8')\n",
    "\n",
    "# photo就是原数据，yelp上下载的\n",
    "pic_df = pd.read_excel('./data/excel/photos.xlsx')\n",
    "# print(pic_df)\n",
    "\n",
    "pic_df['memory_score'] = 0\n",
    "pic_df['h'] = 0\n",
    "pic_df['s'] = 0\n",
    "pic_df['v'] = 0\n",
    "\n",
    "for index,row in pic_df.iterrows():\n",
    "    # print(index,row['photo_id'],row['business_id'],row['caption'],row['label'])\n",
    "    pic_path = './data/pic/'+row['photo_id']+'.jpg'\n",
    "    print(pic_path)\n",
    "    try:\n",
    "        pic_score = pic_score_pre(pic_path)\n",
    "        h,s,v = get_hsv(pic_path)\n",
    "        pic_df.iloc[index,-4] = pic_score\n",
    "        pic_df.iloc[index,-3] = h\n",
    "        pic_df.iloc[index,-2] = s\n",
    "        pic_df.iloc[index,-1] = v\n",
    "        print('    '.join([row['photo_id'],str(pic_score),str(h),str(s),str(v)]),file=fs)\n",
    "        print('    '.join([row['photo_id'],str(pic_score),str(h),str(s),str(v)]))\n",
    "    except:\n",
    "        print(row['photo_id'],file=fs)\n",
    "        # pass\n",
    "\n",
    "pic_df.to_excel('./data/excel/photos_detail.xlsx',index=False) \n",
    "# photo_detail 就是 photo_result\n",
    "\n",
    "\n",
    "# # pic_df= pic_df.head(5)\n",
    "\n",
    "# col_name = ['business_id','pic_count','pic_type_count','pic_type_content']\n",
    "# for col in ['memory_score','h','s','v']:\n",
    "#     for label in ['inside','outside','menu','drink','food']:\n",
    "#         for calculate in ['avg','max']:\n",
    "#             col_name.append(col+'_'+label+'_'+calculate)\n",
    "\n",
    "# all_calculate = []\n",
    "# for business_id in  pic_df['business_id'].unique():\n",
    "#     line = []\n",
    "#     pic_count = len(pic_df[pic_df['business_id']==business_id]['photo_id'].unique())\n",
    "#     pic_type_count = len(pic_df[pic_df['business_id']==business_id]['label'].unique())\n",
    "#     pic_type_content = pic_df[pic_df['business_id']==business_id]['label'].unique()\n",
    "#     # print(business_id,pic_count,pic_type_count,pic_type_content)\n",
    "#     line.append(business_id)\n",
    "#     line.append(pic_count)\n",
    "#     line.append(pic_type_count)\n",
    "#     line.append(pic_type_content)\n",
    "        \n",
    "#     for col in ['memory_score','h','s','v']:\n",
    "#         for label in ['inside','outside','menu','drink','food']:\n",
    "#             if len(pic_df[(pic_df['business_id']==business_id)&(pic_df['label']==label)][col])==0:\n",
    "#                 avg_v = 0\n",
    "#                 max_v = 0\n",
    "#             else:\n",
    "#                 avg_v = np.sum(pic_df[(pic_df['business_id']==business_id)&(pic_df['label']==label)][col])/len(pic_df[(pic_df['business_id']==business_id)&(pic_df['label']==label)][col])\n",
    "#                 max_v = np.max(pic_df[(pic_df['business_id']==business_id)&(pic_df['label']==label)][col])\n",
    "#             # print(col,label,avg_v,max_v)\n",
    "#             line.append(avg_v)\n",
    "#             line.append(max_v)\n",
    "#     all_calculate.append(line)\n",
    "\n",
    "# pic_df_summary = pd.DataFrame(all_calculate,columns=col_name)\n",
    "\n",
    "# pic_df_summary.to_excel('./data/excel/photos_summary.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------business-----------------------------------------------\n",
    "# 通过 上面的函数将json 转换为 xlsx\n",
    "# 提取部分变量  business_id\tstars\treview_count\tis_open\tcategories_counts   category_counts  是根据 category进行计数统计\n",
    "business = pd.read_excel(\"data/excel/yelp_academic_dataset_business.xlsx\")\n",
    "business = business[['business_id','stars','review_count','is_open','categories','user_count']]\n",
    "business['categories_counts'] = business['categories'].str.split(',').str.len()\n",
    "business.to_excel(\"./data/excel/business_result.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94c9cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protect_excel_formula(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: f\"'{x}\" if isinstance(x, str) and x.startswith(('=', '+', '-', '@')) else x\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据的合并\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "business = pd.read_excel('./data/excel/business_result.xlsx')\n",
    "review = pd.read_csv('./data/excel/review_result.csv')\n",
    "# tips = pd.read_csv('./data/excel/tips_result.csv')\n",
    "# photos_detail 等于 photos_result\n",
    "# photos = pd.read_excel(\"./data/excel/photos_result.xlsx\")\n",
    "# 数据格式处理\n",
    "business = protect_excel_formula(business)\n",
    "df1 = pd.merge(business,review,left_on='business_id',right_on='business_id',how='left')\n",
    "\n",
    "# # 过滤掉name没有识别出来的数据\n",
    "# result = df1.dropna()\n",
    "\n",
    "df1.to_csv('./data/excel/business_feature.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a3b3a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150346 Index(['business_id', 'stars', 'review_count', 'is_open', 'categories_counts',\n",
      "       'user_count', 'star_avg', 'star_std', 'contents_score_avg',\n",
      "       'useful_avg', 'funny_avg', 'cool_avg'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(df1),df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dcd6567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6990280"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('./data/excel/yelp_academic_dataset_review.csv')\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973161df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
