{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84679057",
   "metadata": {},
   "source": [
    "# picture跑模型数据生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862ddc5",
   "metadata": {},
   "source": [
    "picture的特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "573af216",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 1:HSV\n",
    "\n",
    "# pip install opencv-python-headless\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_average_hsv(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convert the image from BGR to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # Calculate the average hue, saturation, and value\n",
    "    average_hue = np.mean(hsv_image[:, :, 0])\n",
    "    average_saturation = np.mean(hsv_image[:, :, 1])\n",
    "    average_value = np.mean(hsv_image[:, :, 2])\n",
    "    return average_hue, average_saturation, average_value\n",
    "\n",
    "# # 对 h s v进行大标签\n",
    "# def categorize_image_by_average_hue(average_hue):\n",
    "#     # Adjusting for the scale wrapping of red\n",
    "#     if (0 <= average_hue <= 34) or (170 <= average_hue <= 179):\n",
    "#         return 'Warm Dominant'\n",
    "#     else:\n",
    "#         return 'Cool Dominant'\n",
    "\n",
    "\n",
    "# def classify_saturation(average_saturation):\n",
    "#     saturation_category = \"Low\" if average_saturation < 64 else \"High\" if average_saturation > 191 else \"Medium\"\n",
    "#     return saturation_category\n",
    "\n",
    "\n",
    "# def classify_saturation(average_value):\n",
    "#     value_category = \"Low\" if average_value < 64 else \"High\" if average_value > 191 else \"Medium\"\n",
    "#     return value_category\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# image_path = '1.png'\n",
    "# average_hue, average_saturation, average_value = calculate_average_hsv(image_path)\n",
    "# print([average_hue, average_saturation, average_value])\n",
    "\n",
    "# h_cate = categorize_image_by_average_hue(average_hue)\n",
    "# s_cate = classify_saturation(average_saturation)\n",
    "# v_cate = classify_saturation(average_value)\n",
    "# print(h_cate,s_cate,v_cate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d806b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 2: smilling face detect \n",
    "\n",
    "import cv2\n",
    "\n",
    "def detect_smiling_faces(image_path):\n",
    "    # Load the Haar Cascade classifiers for face and smile detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    smiling_faces_count = 0\n",
    "    \n",
    "    # For each detected face, look for a smile\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "        smiles = smile_cascade.detectMultiScale(face_roi, scaleFactor=1.8, minNeighbors=20, minSize=(25, 25), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        \n",
    "        # If at least one smile is detected in the face ROI, count the face as smiling\n",
    "        if len(smiles) > 0:\n",
    "            smiling_faces_count += 1\n",
    "            \n",
    "    return smiling_faces_count\n",
    "\n",
    "# # Example usage\n",
    "# image_path = '3.png'\n",
    "# smiling_faces = detect_smiling_faces(image_path)\n",
    "# print(f\"Number of smiling faces detected: {smiling_faces}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed35461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3: Clarity\n",
    "\n",
    "# pip install opencv-python-headless\n",
    "\n",
    "import cv2\n",
    "\n",
    "def quantify_image_quality_and_clarity(image_path):\n",
    "    # Load the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply the Laplacian operator to the image\n",
    "    laplacian_var = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    \n",
    "    return laplacian_var\n",
    "\n",
    "# # Example usage\n",
    "# image_path = '1.png'\n",
    "# sharpness_measure = quantify_image_quality_and_clarity(image_path)\n",
    "# print(f\"Sharpness (Variance of Laplacian): {sharpness_measure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "532403c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 4: Textual Details 图片识别文本\n",
    "### 2 outcome variable (text; positive&negative)\n",
    "\n",
    "\n",
    "# pip install pytesseract pillow\n",
    "# import pytesseract\n",
    "\n",
    "# https://blog.csdn.net/yuan2019035055/article/details/129754864\n",
    "\n",
    "# from PIL import Image\n",
    "# import pytesseract\n",
    "\n",
    "# def detect_text(image_path):\n",
    "#     # Load the image\n",
    "#     image = Image.open(image_path)\n",
    "    \n",
    "#     # Use Pytesseract to detect text\n",
    "#     text = pytesseract.image_to_string(image)\n",
    "    \n",
    "#     return text.strip()\n",
    "\n",
    "# # Example usage\n",
    "# image_path = '1.png'\n",
    "# detected_text = detect_text(image_path)\n",
    "# print(detected_text)\n",
    "# if detected_text:\n",
    "#     print(f\"Detected text: {detected_text}\")\n",
    "# else:\n",
    "#     print(\"No text detected in the image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1da473",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 5: color diversity\n",
    "### 1 outcome variable (uniqueness_score)\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def quantify_color_uniqueness(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convert to HSV for more meaningful color analysis\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # Flatten the image array and calculate unique colors\n",
    "    unique_colors = np.unique(hsv_image.reshape(-1, hsv_image.shape[2]), axis=0)\n",
    "    # The number of unique colors can serve as a basic proxy for uniqueness\n",
    "    color_uniqueness_score = len(unique_colors)\n",
    "    return color_uniqueness_score\n",
    "\n",
    "# # Example usage\n",
    "# image_path = '1.png'\n",
    "# uniqueness_score = quantify_color_uniqueness(image_path)\n",
    "# print(f\"Color Uniqueness Score: {uniqueness_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 6: object detection ===> yolo11  tf2(Python3.8.0)的环境可以跑   图片识别物体\n",
    "### 1 outcome variable (uniqueness_score)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "model = YOLO('data/pic/yolo11n.pt')  # load a pretrained YOLO detection model\n",
    "\n",
    "\n",
    "def detect_pic_object(path):\n",
    "  try:\n",
    "    res = []\n",
    "    results = model(path)  # predict on an image\n",
    "    # 遍历每个检测结果\n",
    "    for i, result in enumerate(results):\n",
    "        # 打印图像路径\n",
    "        print(f\"Image {i + 1}: {result.path}\")\n",
    "        # 获取检测框、类别和置信度\n",
    "        boxes = result.boxes  # Boxes object for bbox outputs\n",
    "        masks = result.masks  # Masks object for segmentation masks outputs (if applicable)\n",
    "        probs = result.probs  # Class probabilities (classification only)\n",
    "        # 打印每个检测框的信息\n",
    "        for box in boxes:\n",
    "            cls = box.cls  # 类别ID\n",
    "            # 假设你有一个类别名称列表\n",
    "            class_names = model.names  # 获取模型的类别名称映射\n",
    "            class_name = class_names[int(cls)]  # 将类别ID转换为类别名称\n",
    "            # 打印检测结果\n",
    "            # print(class_name)\n",
    "            res.append(class_name)\n",
    "  except:\n",
    "     res = ''\n",
    "  return res\n",
    "\n",
    "\n",
    "# fs = open('data/pic/result_object_detect_yolo11.txt','a+',encoding='utf-8')\n",
    "# count = 0\n",
    "# # for item in os.listdir(\"pic_data\")[:]:\n",
    "# for item in os.listdir(\"photos\")[:]:\n",
    "#     count+=1\n",
    "#     print(count,item)\n",
    "#     all_path = \"photos\"+'//'+item\n",
    "#     res = detect_pic_object(all_path)\n",
    "#     print([item.split('.')[0]+\"&\"+str(res)], file=fs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6023807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory score\n",
    "\n",
    "from resmem import ResMem, transformer\n",
    "model = ResMem(pretrained=True)\n",
    "\n",
    "def pic_score_pre(pic_path):\n",
    "    img = Image.open(pic_path) # This loads your image into memory\n",
    "    img = img.convert('RGB') \n",
    "    # This will convert your image into RGB, for instance if it's a PNG (RGBA) or if it's black and white.\n",
    "    model.eval()\n",
    "    # Set the model to inference mode.\n",
    "    image_x = transformer(img)\n",
    "    # Run the preprocessing function\n",
    "    # print(image_x.shape)\n",
    "    prediction = model(image_x.view(-1, 3, 227, 227))\n",
    "    # For a single image, the image must be reshaped into a batch\n",
    "    # with size 1.\n",
    "    # Get your prediction!\n",
    "    return round(prediction[0][0].item(),3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# fs = open('result.txt','a+',encoding='utf-8')\n",
    "# path =r'\\yelp_memory\\data\\pic'\n",
    "\n",
    "# count = 0\n",
    "# result = []\n",
    "# for pic in os.listdir(path)[:]:\n",
    "#     count+=1\n",
    "#     print(count,pic.split('.')[0])\n",
    "#     # print(count,path+'\\\\'+pic,pic.split('.')[0])\n",
    "#     image_path = path+'\\\\'+pic\n",
    "#     average_hue, average_saturation, average_value = calculate_average_hsv(image_path)\n",
    "#     # print([average_hue, average_saturation, average_value])\n",
    "#     number_face,smiling_faces_count = detect_smiling_faces(image_path)\n",
    "#     # print(smiling_faces_count)\n",
    "#     sharpness_measure = quantify_image_quality_and_clarity(image_path)\n",
    "#     # print(sharpness_measure)\n",
    "#     detected_text = detect_text(image_path)\n",
    "#     # print(detected_text)\n",
    "#     uniqueness_score = quantify_color_uniqueness(image_path)\n",
    "#     # print(uniqueness_score)\n",
    "#     object_detection= detect_pic_object(image_path)\n",
    "#     # print(object_detection)\n",
    "\n",
    "#     print([pic.split('.')[0],\n",
    "#                   average_hue, average_saturation, average_value,\n",
    "#                   number_face,\n",
    "#                   smiling_faces_count,\n",
    "#                   sharpness_measure,\n",
    "#                   detected_text,\n",
    "#                   uniqueness_score,\n",
    "#                  # object_detection\n",
    "# ],file=fs)\n",
    "    \n",
    "#     result.append([pic.split('.')[0],\n",
    "#                   average_hue, average_saturation, average_value,\n",
    "#                   number_face,\n",
    "#                   smiling_faces_count,\n",
    "#                   sharpness_measure,\n",
    "#                   detected_text,\n",
    "#                   uniqueness_score,\n",
    "#                #   object_detection\n",
    "#                  ]\n",
    "#                   )\n",
    "\n",
    "# result_df = pd.DataFrame(result,columns=['pic_filename',\n",
    "#                   'average_hue', 'average_saturation', 'average_value',\n",
    "#                   'number_face','smiling_faces_count','sharpness_measure','detected_text','uniqueness_score'\n",
    "#                  # ,\"object_detection\"\n",
    "#])\n",
    "\n",
    "# result_df.to_excel('generate_result.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdb6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据保存成功！\n"
     ]
    }
   ],
   "source": [
    "# 处理yolo的数据 生成3个变量\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "person_result = []\n",
    "\n",
    "with open(\"data/pic/result_object_detect_yolo11.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines[:]:\n",
    "        name,detect_content = l.split(\"&\")\n",
    "        pic_name = name.replace('[\"',\"\").replace(\"['\",\"\")\n",
    "        pic_detect_content = str(detect_content).replace('[',\"\").replace(']',\"\").replace(\"'\",\"\").replace('\"','')\n",
    "        person_count = detect_content.count(\"person\")\n",
    "        # person_judge = str(detect_content).find(\"person\")\n",
    "        if person_count==0:\n",
    "            person_exist = 0\n",
    "        else:\n",
    "            person_exist = 1\n",
    "\n",
    "        # print(pic_name,\n",
    "        #       person_count,\n",
    "        #       person_exist,\n",
    "        #       pic_detect_content\n",
    "        #       )\n",
    "        person_result.append([pic_name,str(person_count),str(person_exist),pic_detect_content])\n",
    "\n",
    "pd.DataFrame(person_result,columns=['photo_id','person_count','person_exist','objects_content']).to_excel(\"data/pic/person_result.xlsx\",index=False)\n",
    "print(\"数据保存成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98528c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 图片构图位置 和图片美学（如果需要执行这个代码，需要把这段放在数据导入的下面）\n",
    "# df3_position = pd.read_excel('data/pic/图像位置构图结果.xlsx',header=None)\n",
    "# df3_position[0]=df3_position[0].str.replace('\"',\"\")\n",
    "# df3_position[0]=df3_position[0].str.replace('.jpg',\"\")\n",
    "# # df3_position.head()\n",
    "# df4_beauty = pd.read_csv('data/pic/图片美学.csv',header=None)\n",
    "# df4_beauty[0]=df4_beauty[0].str.replace('.jpg',\"\")\n",
    "# # df4_beauty.head()\n",
    "\n",
    "# pic1 = pd.merge(pic,df3_position,left_on='pic_filename',right_on=0,how='left')\n",
    "# pic2 = pd.merge(pic1,df4_beauty,left_on='pic_filename',right_on=0,how='left')\n",
    "# pic2.rename(columns={'1_x': 'pic_position','1_y':\"pic_beauty\"}, inplace=True)\n",
    "# pic2 = pic2.drop(['0_x', '0_y'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522b13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据格式的处理函数\n",
    "def protect_excel_formula(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: f\"'{x}\" if isinstance(x, str) and x.startswith(('=', '+', '-', '@')) else x\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911be3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150346 200098 200098 199994\n"
     ]
    }
   ],
   "source": [
    "# 对yolo11的结果进行处理并合并到generate_result数据上\n",
    "import pandas as pd\n",
    "\n",
    "business = pd.read_excel(\"data/excel/yelp_academic_dataset_business.xlsx\")\n",
    "# 遍历图片路径生成（特征变量）最终生成 generate_result数据集\n",
    "pic = pd.read_excel(\"data/pic/generate_result.xlsx\")\n",
    "# yolo11的检测结果处理后的变量\n",
    "person_result = pd.read_excel(\"data/pic/person_result.xlsx\")\n",
    "pic_bus = pd.read_excel(\"data/excel/photos_result.xlsx\")\n",
    "# 对于为什么要过滤掉0的数据，因为部分图片是坏掉的，所以memory score是0\n",
    "pic_bus = pic_bus[pic_bus['memory_score']!=0]\n",
    "print(len(business),len(pic),len(person_result),len(pic_bus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34085b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199994 Index(['photo_id', 'business_id', 'caption', 'label', 'memory_score',\n",
      "       'pic_filename', 'average_hue', 'average_saturation', 'average_value',\n",
      "       'number_face', 'smiling_faces_count', 'sharpness_measure',\n",
      "       'detected_text', 'uniqueness_score', 'person_count', 'person_exist',\n",
      "       'objects_content', 'name', 'address', 'city', 'state', 'postal_code',\n",
      "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
      "       'attributes', 'categories', 'hours'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# # pic number 数据量 199994\n",
    "df1 = pd.merge(pic_bus[[\"photo_id\",\"business_id\",\"caption\",\"label\",\"memory_score\"]],pic,\n",
    "               left_on = \"photo_id\",right_on=\"pic_filename\")\n",
    "df2 = pd.merge(df1,person_result,on=\"photo_id\")\n",
    "df3 = pd.merge(df2,business,how='left',on=\"business_id\")\n",
    "df3.loc[df3['caption'].isnull(),'caption'] = 0\n",
    "df3.loc[~df3['caption'].isnull(),'caption'] = 1\n",
    "df3 = protect_excel_formula(df3)\n",
    "df3.to_excel(\"data/pic/pic_feature.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11719458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199994 Index(['photo_id', 'business_id', 'caption', 'label', 'memory_score',\n",
      "       'pic_filename', 'average_hue', 'average_saturation', 'average_value',\n",
      "       'number_face', 'smiling_faces_count', 'sharpness_measure',\n",
      "       'detected_text', 'uniqueness_score', 'person_count', 'person_exist',\n",
      "       'objects_content', 'name', 'address', 'city', 'state', 'postal_code',\n",
      "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
      "       'attributes', 'categories', 'hours'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(df3),df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993fcc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
