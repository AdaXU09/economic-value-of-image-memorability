{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1747915200448,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "bdnyawJ5burm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from linearmodels.iv import IV2SLS\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41387,
     "status": "ok",
     "timestamp": 1747915573453,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "gr0zhIadcdKN",
    "outputId": "c9f40c6d-1e27-4827-b248-8f0824ef9a09"
   },
   "outputs": [],
   "source": [
    "# import pic data\n",
    "all_pic_temp = pd.read_excel(\"data/input/open_pic_new.xlsx\")\n",
    "res_pic_temp = pd.read_excel(\"data/input/restaurant_new.xlsx\")\n",
    "drink_pic_temp = pd.read_excel(\"data/input/drink_new.xlsx\")\n",
    "# import business data \n",
    "business_feature_df = pd.read_csv(\"data/input/business_feature.csv\")\n",
    "\n",
    "# add photo count per business\n",
    "photo_count = all_pic_temp.groupby('business_id').size().reset_index(name='photo_count')\n",
    "business_feature_df = business_feature_df.merge(photo_count, on='business_id', how='left')\n",
    "business_feature_df['photo_count'] = business_feature_df['photo_count'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752 0.412 0.993\n",
      "0.749 0.412 0.993\n",
      "0.74 0.412 0.991\n"
     ]
    }
   ],
   "source": [
    "print(round(all_pic_temp[\"memory_score\"].mean(),3),all_pic_temp[\"memory_score\"].min(),all_pic_temp[\"memory_score\"].max())\n",
    "print(round(res_pic_temp[\"memory_score\"].mean(),3),res_pic_temp[\"memory_score\"].min(),res_pic_temp[\"memory_score\"].max())\n",
    "print(round(drink_pic_temp[\"memory_score\"].mean(),3),drink_pic_temp[\"memory_score\"].min(),drink_pic_temp[\"memory_score\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164839, 31) (139385, 31) (73268, 33) (150346, 13)\n"
     ]
    }
   ],
   "source": [
    "# data shape\n",
    "print(all_pic_temp.shape,res_pic_temp.shape,drink_pic_temp.shape,business_feature_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df_open):\n",
    "  # filter yolo nan data\n",
    "    var = []\n",
    "    person_other_count = []\n",
    "    person_total_count = []\n",
    "    for index,row in df_open.iterrows():\n",
    "        if len(str(row['objects_content']))==1 or len(str(row['objects_content']))==0:\n",
    "            temp = ''\n",
    "        else:\n",
    "            # 'object_content' columns str to list\n",
    "            temp = str(row['objects_content']).split(\",\")\n",
    "            temp = [s.strip() for s in temp]\n",
    "        person_count = temp.count('person')\n",
    "        other_count = len(temp)-person_count\n",
    "        temp_res = abs(person_count-other_count)\n",
    "        try:\n",
    "            var_temp = temp_res/(person_count+other_count)\n",
    "        except:\n",
    "            var_temp = 0\n",
    "        var.append(var_temp)\n",
    "        person_total_count.append(len(temp))\n",
    "    df_open['var'] = var\n",
    "    df_open['person_total_count'] = person_total_count\n",
    "    df_open['person_total_count_cluster'] = np.where(df_open['person_total_count'] != 0, 1, df_open['person_total_count'])\n",
    "    # print(df_open['person_total_count_cluster'].value_counts())\n",
    "    filter_data  = df_open[df_open['person_total_count']!=0]\n",
    "    print(\"pre process data len:\",len(df_open),\"post process data len: \",len(filter_data))\n",
    "    return df_open[df_open['person_total_count']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26678,
     "status": "ok",
     "timestamp": 1747915612212,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "XubRG004burs",
    "outputId": "91c5fedc-7778-415c-8f4f-8f632c2f3ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre process data len: 164839 post process data len:  154945\n",
      "business      label  memory_score\n",
      "0    drink      0.830912\n",
      "1     food      0.788275\n",
      "2   inside      0.668729\n",
      "3     menu      0.826144\n",
      "4  outside      0.690957\n",
      "pre process data len: 139385 post process data len:  131624\n",
      "res_df      label  memory_score\n",
      "0    drink      0.826183\n",
      "1     food      0.783535\n",
      "2   inside      0.659904\n",
      "3     menu      0.827708\n",
      "4  outside      0.688542\n",
      "pre process data len: 73268 post process data len:  69548\n",
      "drink_df      label  memory_score\n",
      "0    drink      0.831727\n",
      "1     food      0.782448\n",
      "2   inside      0.662736\n",
      "3     menu      0.824719\n",
      "4  outside      0.676933\n"
     ]
    }
   ],
   "source": [
    "# pic process\n",
    "all_df_pic = process_data(all_pic_temp)\n",
    "print(\"business\",all_df_pic[['label','memory_score']].groupby('label').mean().reset_index())\n",
    "res_df_pic = process_data(res_pic_temp)\n",
    "print(\"res_df\",res_df_pic[['label','memory_score']].groupby('label').mean().reset_index())\n",
    "drink_df_pic = process_data(drink_pic_temp)\n",
    "print(\"drink_df\",drink_df_pic[['label','memory_score']].groupby('label').mean().reset_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "文件已保存至: data/output/bubble_plot_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "def calculate_bubble_data(df, group_name):\n",
    "    \"\"\"计算气泡图需要的统计量\"\"\"\n",
    "    stats = df.groupby('label')['memory_score'].agg(\n",
    "        memory_score='mean',      # 平均值\n",
    "        sd='std',                 # 标准差\n",
    "        n='count'                 # 样本量\n",
    "    ).reset_index()\n",
    "   \n",
    "    # 计算百分比\n",
    "    total_n = stats['n'].sum()\n",
    "    stats['percentage'] = (stats['n'] / total_n * 100)\n",
    "    \n",
    "    # 计算标准误和95% CI\n",
    "    stats['se'] = stats['sd'] / np.sqrt(stats['n'])\n",
    "    stats['ci_lower'] = stats['memory_score'] - 1.96 * stats['se']\n",
    "    stats['ci_upper'] = stats['memory_score'] + 1.96 * stats['se']\n",
    "    \n",
    "    # 添加分组标签\n",
    "    stats['group'] = group_name\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# ====================== 计算三组数据 ======================\n",
    "all_business_stats = calculate_bubble_data(all_df_pic, \"All businesses\")\n",
    "restaurant_stats = calculate_bubble_data(res_df_pic, \"Restaurants\")\n",
    "drink_stats = calculate_bubble_data(drink_df_pic, \"Drinks\")\n",
    "\n",
    "# ====================== 合并并保存 ======================\n",
    "# 合并三个数据框\n",
    "bubble_data = pd.concat([all_business_stats, restaurant_stats, drink_stats], ignore_index=True)\n",
    "\n",
    "# 调整列顺序\n",
    "bubble_data = bubble_data[['group', 'label', 'memory_score', 'sd', 'n', 'percentage', 'se', 'ci_lower', 'ci_upper']]\n",
    "\n",
    "# # 查看数据\n",
    "# print(bubble_data)\n",
    "\n",
    "# 保存为CSV文件\n",
    "bubble_data.to_excel(\"data/output/bubble_plot_data.xlsx\", index=False)\n",
    "\n",
    "print(\"\\n文件已保存至: data/output/bubble_plot_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747915614109,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "MD77SaGRfmrW",
    "outputId": "9c7568ef-5df4-4fb0-8ee2-880732e9f8ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751 0.412 0.993\n",
      "0.748 0.412 0.993\n",
      "0.74 0.412 0.991\n"
     ]
    }
   ],
   "source": [
    "print(round(all_df_pic[\"memory_score\"].mean(),3),all_df_pic[\"memory_score\"].min(),all_df_pic[\"memory_score\"].max())\n",
    "print(round(res_df_pic[\"memory_score\"].mean(),3),res_df_pic[\"memory_score\"].min(),res_df_pic[\"memory_score\"].max())\n",
    "print(round(drink_df_pic[\"memory_score\"].mean(),3),drink_df_pic[\"memory_score\"].min(),drink_df_pic[\"memory_score\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1747915616168,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "4LoJQhDmburs",
    "outputId": "548c7e64-71bd-44e6-a9a0-25d30cb9ccab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27075 21279 9853\n"
     ]
    }
   ],
   "source": [
    "# business_feature data process\n",
    "business_df =  business_feature_df[business_feature_df['business_id'].isin(list(all_df_pic['business_id'].unique()))]\n",
    "business_res = business_feature_df[business_feature_df['business_id'].isin(list(res_df_pic['business_id'].unique()))]\n",
    "business_drink = business_feature_df[business_feature_df['business_id'].isin(list(drink_df_pic['business_id'].unique()))]\n",
    "# 22397 18203 8192\n",
    "\n",
    "# pic 数据的转换\n",
    "# print(len(business_df),len(business_res),len(business_drink))\n",
    "\n",
    "business_df = pd.merge(business_df,all_df_pic[[\"business_id\",\"memory_score\",\"average_hue\",\"average_saturation\",\n",
    "                                               \"average_value\",\"sharpness_measure\",\"person_count\",\"beauty_score\",'person_total_count']].groupby(\"business_id\").mean().reset_index(),\n",
    "                       how='left',on='business_id')\n",
    "business_res = pd.merge(business_res,res_df_pic[[\"business_id\",\"memory_score\",\"average_hue\",\"average_saturation\",\n",
    "                                               \"average_value\",\"sharpness_measure\",\"person_count\",\"beauty_score\",'person_total_count']].groupby(\"business_id\").mean().reset_index(),\n",
    "                       how='left',on='business_id')\n",
    "business_drink = pd.merge(business_drink,drink_df_pic[[\"business_id\",\"memory_score\",\"average_hue\",\"average_saturation\",\n",
    "                                               \"average_value\",\"sharpness_measure\",\"person_count\",\"beauty_score\",'person_total_count']].groupby(\"business_id\").mean().reset_index(),\n",
    "                       how='left',on='business_id')\n",
    "print(len(business_df),len(business_res),len(business_drink))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26769 21150 9751\n"
     ]
    }
   ],
   "source": [
    "business_df = business_df[(business_df['star_std']!=0)].reset_index(drop=True)\n",
    "business_res = business_res[(business_res['star_std']!=0)].reset_index(drop=True)\n",
    "business_drink = business_drink[(business_drink['star_std']!=0)].reset_index(drop=True)\n",
    "print(len(business_df),len(business_res),len(business_drink))\n",
    "\n",
    "# print(len(all_bus), len(all_res), len(all_drink))\n",
    "# print(len(business_df), len(business_res), len(business_drink))\n",
    "# print(len(all_bus)-len(business_df), len(all_res)-len(business_res), len(all_drink)-len(business_drink))\n",
    "# print(round((len(all_bus)-len(business_df))/len(all_bus),3),\n",
    "#        round((len(all_bus)-len(business_df))/len(all_res),3), \n",
    "#        round((len(all_bus)-len(business_df))/len(all_drink),3))\n",
    "\n",
    "# 27075 21279 9853\n",
    "# 26769 21150 9751\n",
    "# 306 129 102\n",
    "# 0.011 0.014 0.031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456545\n",
      "3155433\n",
      "1481608\n"
     ]
    }
   ],
   "source": [
    "print(business_df['review_count'].sum())\n",
    "print(business_res['review_count'].sum())\n",
    "print(business_drink['review_count'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whOXRxzxswpI"
   },
   "source": [
    "# study 1 :image feature ---- memorability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1747915621127,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "IRWAlDstburt"
   },
   "outputs": [],
   "source": [
    "# pic 均值和标准差的统计\n",
    "def result_mean(data):\n",
    "    res = [round(data['memory_score'].mean(),3),\n",
    "    round(len(data[data['label']=='food'])/len(data),3),\n",
    "    round(len(data[data['label']=='menu'])/len(data),3),\n",
    "    round(len(data[data['label']=='inside'])/len(data),3),\n",
    "    round(len(data[data['label']=='outside'])/len(data),3),\n",
    "    round(len(data[data['label']=='drink'])/len(data),3),\n",
    "    round(data['average_hue'].mean(),3),\n",
    "    round(data['average_saturation'].mean(),3),\n",
    "    round(data['average_value'].mean(),3),\n",
    "    round(len(data[data['person_exist']==1])/len(data),3),\n",
    "    # round(data['person_count'].mean(),3),\n",
    "    round(data['var'].mean(),3),\n",
    "    round(data['person_total_count'].mean(),3),\n",
    "    round(data['sharpness_measure'].mean(),3),\n",
    "    round(data['beauty_score'].mean(),3)\n",
    "    ]\n",
    "    return res\n",
    "\n",
    "def result_std(data):\n",
    "    res = [\n",
    "    round(data['memory_score'].std(),3),\n",
    "    '-','-','-','-','-',\n",
    "    round(data['average_hue'].std(),3),\n",
    "    round(data['average_saturation'].std(),3),\n",
    "    round(data['average_value'].std(),3),\n",
    "    '-',\n",
    "    # round(data['person_count'].std(),3),\n",
    "    round(data['var'].std(),3),\n",
    "    round(data['person_total_count'].std(),3),\n",
    "    round(data['sharpness_measure'].std(),3),\n",
    "    round(data['beauty_score'].std(),3)\n",
    "    ]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1747915624401,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "7d1CMyvyburt",
    "outputId": "6c4b48de-cc2d-4248-e9c6-1159402d390a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name  All Busi mean All Busi std  All Res mean All Res std  \\\n",
      "0         memory_score          0.751        0.106         0.748       0.105   \n",
      "1                 food          0.547            -         0.591           -   \n",
      "2                 menu          0.006            -         0.007           -   \n",
      "3               inside          0.277            -         0.254           -   \n",
      "4              outside          0.083            -         0.077           -   \n",
      "5                drink          0.086            -         0.071           -   \n",
      "6          average_hue         40.808       22.614        39.745      21.768   \n",
      "7   average_saturation        101.648        39.34       103.231      38.646   \n",
      "8        average_value        141.041       41.988       141.740      40.902   \n",
      "9         person_exist          0.332            -         0.316           -   \n",
      "10                 var          0.824        0.307         0.830       0.302   \n",
      "11  person_total_count          5.605        4.859         5.642       4.908   \n",
      "12   sharpness_measure       1111.296      970.876      1093.355     952.865   \n",
      "13        beauty_score          5.098        0.343         5.101        0.34   \n",
      "\n",
      "    Drink mean Drink std  \n",
      "0        0.740      0.11  \n",
      "1        0.439         -  \n",
      "2        0.006         -  \n",
      "3        0.333         -  \n",
      "4        0.088         -  \n",
      "5        0.134         -  \n",
      "6       42.306     23.35  \n",
      "7      100.888    39.967  \n",
      "8      134.641    43.248  \n",
      "9        0.376         -  \n",
      "10       0.798     0.323  \n",
      "11       5.961       5.0  \n",
      "12    1101.184    951.96  \n",
      "13       5.089     0.342  \n",
      "数据保存成功\n"
     ]
    }
   ],
   "source": [
    "# pic 均值和标准差的统计结果\n",
    "data = {\n",
    "    \"name\":[\"memory_score\",\"food\",\"menu\",\"inside\",\n",
    "            \"outside\",\"drink\",\"average_hue\",\"average_saturation\",\n",
    "            \"average_value\",\"person_exist\",\"var\",\"person_total_count\",\"sharpness_measure\",\"beauty_score\"],\n",
    "    'All Busi mean': result_mean(all_df_pic),\n",
    "    'All Busi std': result_std(all_df_pic),\n",
    "    'All Res mean': result_mean(res_df_pic),\n",
    "    'All Res std': result_std(res_df_pic),\n",
    "    'Drink mean': result_mean(drink_df_pic),\n",
    "    'Drink std': result_std(drink_df_pic)\n",
    "    }\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 显示DataFrame\n",
    "print(df)\n",
    "df.head()\n",
    "df.to_excel(\"data/output/study1_picture_data_summary_yolo11.xlsx\",index=False)\n",
    "print(\"数据保存成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747915625669,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "HpxtmtMhburw"
   },
   "outputs": [],
   "source": [
    "def create_ols_model(data):\n",
    "    df_dummies = pd.get_dummies(data['label'])\n",
    "    df_dummies = df_dummies[['food','menu','inside','drink']].astype(int)\n",
    "    df = pd.concat([data, df_dummies], axis=1)\n",
    "    # use StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    df['average_hue_s'] = scaler.fit_transform(df[['average_hue']])\n",
    "    df['average_saturation_s'] = scaler.fit_transform(df[['average_saturation']])\n",
    "    df['average_value_s'] = scaler.fit_transform(df[['average_value']])\n",
    "    df['var'] = df[['var']]\n",
    "    df['sharpness_measure_s'] = scaler.fit_transform(df[['sharpness_measure']])\n",
    "    X =  df[list(df_dummies.columns)+['average_hue_s','average_saturation_s','average_value_s',\n",
    "                                      'person_exist',\n",
    "                                      'var',\n",
    "                                      \"person_total_count\"\n",
    "                                      ,'beauty_score','sharpness_measure_s'\n",
    "                                      ]]\n",
    "    y = data['memory_score']\n",
    "    X = sm.add_constant(X)\n",
    "    # Business-clustered SE to account for within-business dependence (Comment 1 fix)\n",
    "    model = sm.OLS(y, X).fit(cov_type='cluster',\n",
    "                              cov_kwds={'groups': data['business_id']})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------1.all--------------------------------------------------\n",
      "pre process data len: 154945 post process data len:  154945\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           memory_score   R-squared:                       0.365\n",
      "Model:                            OLS   Adj. R-squared:                  0.365\n",
      "Method:                 Least Squares   F-statistic:                     4041.\n",
      "Date:                Wed, 18 Feb 2026   Prob (F-statistic):               0.00\n",
      "Time:                        15:41:26   Log-Likelihood:             1.6271e+05\n",
      "No. Observations:              154945   AIC:                        -3.254e+05\n",
      "Df Residuals:                  154932   BIC:                        -3.253e+05\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:              cluster                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.6813      0.005    142.691      0.000       0.672       0.691\n",
      "food                     0.0854      0.002     55.850      0.000       0.082       0.088\n",
      "menu                     0.1191      0.003     38.874      0.000       0.113       0.125\n",
      "inside                  -0.0007      0.002     -0.453      0.650      -0.004       0.002\n",
      "drink                    0.1360      0.002     86.238      0.000       0.133       0.139\n",
      "average_hue_s            0.0035      0.000     10.703      0.000       0.003       0.004\n",
      "average_saturation_s    -0.0026      0.000     -7.860      0.000      -0.003      -0.002\n",
      "average_value_s          0.0178      0.000     52.686      0.000       0.017       0.018\n",
      "person_exist             0.0050      0.001      4.116      0.000       0.003       0.007\n",
      "var                     -0.0094      0.002     -5.783      0.000      -0.013      -0.006\n",
      "person_total_count      -0.0039    6.9e-05    -57.193      0.000      -0.004      -0.004\n",
      "beauty_score             0.0076      0.001      7.881      0.000       0.006       0.010\n",
      "sharpness_measure_s      0.0018      0.000      5.611      0.000       0.001       0.002\n",
      "==============================================================================\n",
      "Omnibus:                       52.550   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               49.797\n",
      "Skew:                          -0.023   Prob(JB):                     1.54e-11\n",
      "Kurtosis:                       2.925   Cond. No.                         148.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "--------------------------------------------------2.res_data--------------------------------------------------\n",
      "pre process data len: 131624 post process data len:  131624\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           memory_score   R-squared:                       0.364\n",
      "Model:                            OLS   Adj. R-squared:                  0.364\n",
      "Method:                 Least Squares   F-statistic:                     3251.\n",
      "Date:                Wed, 18 Feb 2026   Prob (F-statistic):               0.00\n",
      "Time:                        15:41:30   Log-Likelihood:             1.4001e+05\n",
      "No. Observations:              131624   AIC:                        -2.800e+05\n",
      "Df Residuals:                  131611   BIC:                        -2.799e+05\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:              cluster                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.6924      0.005    132.805      0.000       0.682       0.703\n",
      "food                     0.0826      0.002     47.340      0.000       0.079       0.086\n",
      "menu                     0.1207      0.003     36.442      0.000       0.114       0.127\n",
      "inside                  -0.0063      0.002     -3.234      0.001      -0.010      -0.002\n",
      "drink                    0.1332      0.002     72.074      0.000       0.130       0.137\n",
      "average_hue_s            0.0023      0.000      5.982      0.000       0.002       0.003\n",
      "average_saturation_s    -0.0018      0.000     -4.760      0.000      -0.003      -0.001\n",
      "average_value_s          0.0163      0.000     45.126      0.000       0.016       0.017\n",
      "person_exist             0.0018      0.002      1.221      0.222      -0.001       0.005\n",
      "var                     -0.0117      0.002     -5.839      0.000      -0.016      -0.008\n",
      "person_total_count      -0.0039   7.72e-05    -50.271      0.000      -0.004      -0.004\n",
      "beauty_score             0.0057      0.001      5.271      0.000       0.004       0.008\n",
      "sharpness_measure_s      0.0019      0.000      5.672      0.000       0.001       0.003\n",
      "==============================================================================\n",
      "Omnibus:                       31.087   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.188\n",
      "Skew:                          -0.010   Prob(JB):                     4.59e-07\n",
      "Kurtosis:                       2.930   Cond. No.                         150.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "--------------------------------------------------3.drink_data--------------------------------------------------\n",
      "pre process data len: 69548 post process data len:  69548\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           memory_score   R-squared:                       0.407\n",
      "Model:                            OLS   Adj. R-squared:                  0.407\n",
      "Method:                 Least Squares   F-statistic:                     2403.\n",
      "Date:                Wed, 18 Feb 2026   Prob (F-statistic):               0.00\n",
      "Time:                        15:41:32   Log-Likelihood:                 72733.\n",
      "No. Observations:               69548   AIC:                        -1.454e+05\n",
      "Df Residuals:                   69535   BIC:                        -1.453e+05\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:              cluster                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                    0.6563      0.008     81.054      0.000       0.640       0.672\n",
      "food                     0.0907      0.002     40.491      0.000       0.086       0.095\n",
      "menu                     0.1355      0.004     33.264      0.000       0.128       0.143\n",
      "inside                   0.0061      0.002      2.546      0.011       0.001       0.011\n",
      "drink                    0.1472      0.002     65.925      0.000       0.143       0.152\n",
      "average_hue_s            0.0045      0.000      9.231      0.000       0.004       0.005\n",
      "average_saturation_s    -0.0025      0.000     -5.875      0.000      -0.003      -0.002\n",
      "average_value_s          0.0206      0.001     40.721      0.000       0.020       0.022\n",
      "person_exist             0.0036      0.002      1.742      0.081      -0.000       0.008\n",
      "var                     -0.0153      0.003     -5.660      0.000      -0.021      -0.010\n",
      "person_total_count      -0.0037      0.000    -35.703      0.000      -0.004      -0.003\n",
      "beauty_score             0.0107      0.002      6.095      0.000       0.007       0.014\n",
      "sharpness_measure_s      0.0006      0.000      1.247      0.213      -0.000       0.002\n",
      "==============================================================================\n",
      "Omnibus:                        1.480   Durbin-Watson:                   1.997\n",
      "Prob(Omnibus):                  0.477   Jarque-Bera (JB):                1.492\n",
      "Skew:                          -0.008   Prob(JB):                        0.474\n",
      "Kurtosis:                       2.985   Cond. No.                         153.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "# ols模型结果\n",
    "print('--------------------------------------------------1.all--------------------------------------------------')\n",
    "ols_business = create_ols_model(process_data(all_df_pic))\n",
    "print(ols_business.summary())\n",
    "print('--------------------------------------------------2.res_data--------------------------------------------------')\n",
    "ols_res = create_ols_model(process_data(res_df_pic))\n",
    "print(ols_res.summary())\n",
    "print('--------------------------------------------------3.drink_data--------------------------------------------------')\n",
    "ols_drink = create_ols_model(process_data(drink_df_pic))\n",
    "print(ols_drink.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21378,
     "status": "ok",
     "timestamp": 1747915649078,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "a1uosrhqmSAy",
    "outputId": "cf50ea07-b783-435a-deaa-b7a11405913d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{OLS Regression Results: Image Memorability (Study 1)}\n",
      "\\label{tab:study1_ols}\n",
      "\\small\n",
      "\\begin{tabular}{l c c c}\n",
      "\\toprule\n",
      " & All businesses & Restaurants & Drinks \\\\\n",
      "\\midrule\n",
      "const & 0.6813*** & 0.6924*** & 0.6563*** \\\\\n",
      " & (0.0048) & (0.0052) & (0.0081) \\\\\n",
      "food & 0.0854*** & 0.0826*** & 0.0907*** \\\\\n",
      " & (0.0015) & (0.0017) & (0.0022) \\\\\n",
      "menu & 0.1191*** & 0.1207*** & 0.1355*** \\\\\n",
      " & (0.0031) & (0.0033) & (0.0041) \\\\\n",
      "inside & -0.0007 & -0.0063** & 0.0061* \\\\\n",
      " & (0.0016) & (0.0019) & (0.0024) \\\\\n",
      "drink & 0.1360*** & 0.1332*** & 0.1472*** \\\\\n",
      " & (0.0016) & (0.0018) & (0.0022) \\\\\n",
      "average\\_hue\\_s & 0.0035*** & 0.0023*** & 0.0045*** \\\\\n",
      " & (0.0003) & (0.0004) & (0.0005) \\\\\n",
      "average\\_saturation\\_s & -0.0026*** & -0.0018*** & -0.0025*** \\\\\n",
      " & (0.0003) & (0.0004) & (0.0004) \\\\\n",
      "average\\_value\\_s & 0.0178*** & 0.0163*** & 0.0206*** \\\\\n",
      " & (0.0003) & (0.0004) & (0.0005) \\\\\n",
      "person\\_exist & 0.0050*** & 0.0018 & 0.0036$^\\dagger$ \\\\\n",
      " & (0.0012) & (0.0015) & (0.0021) \\\\\n",
      "var & -0.0094*** & -0.0117*** & -0.0153*** \\\\\n",
      " & (0.0016) & (0.0020) & (0.0027) \\\\\n",
      "person\\_total\\_count & -0.0039*** & -0.0039*** & -0.0037*** \\\\\n",
      " & (0.0001) & (0.0001) & (0.0001) \\\\\n",
      "beauty\\_score & 0.0076*** & 0.0057*** & 0.0107*** \\\\\n",
      " & (0.0010) & (0.0011) & (0.0018) \\\\\n",
      "sharpness\\_measure\\_s & 0.0018*** & 0.0019*** & 0.0006 \\\\\n",
      " & (0.0003) & (0.0003) & (0.0005) \\\\\n",
      "\\midrule\n",
      "$N$ & 154,945 & 131,624 & 69,548 \\\\\n",
      "$R^2$ & 0.365 & 0.364 & 0.407 \\\\\n",
      "Adj. $R^2$ & 0.365 & 0.364 & 0.407 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{minipage}{\\textwidth}\n",
      "\\vspace{4pt}\n",
      "\\footnotesize\n",
      "\\textit{Note.} Standard errors clustered by business (in parentheses). $^\\dagger p < .10$, $^* p < .05$, $^{**} p < .01$, $^{***} p < .001$.\n",
      "\\end{minipage}\n",
      "\\end{table}\n",
      "\n",
      "Saved: data/output/study1_ols.tex\n"
     ]
    }
   ],
   "source": [
    "# ======================== Study 1 OLS: Custom LaTeX with †/*/**/**** stars ========================\n",
    "\n",
    "def _stars(p):\n",
    "    if p < 0.001: return '***'\n",
    "    if p < 0.01:  return '**'\n",
    "    if p < 0.05:  return '*'\n",
    "    if p < 0.10:  return '$^\\\\dagger$'\n",
    "    return ''\n",
    "\n",
    "def _fmt(val, decimals=4):\n",
    "    return f\"{val:.{decimals}f}\"\n",
    "\n",
    "models = [ols_business, ols_res, ols_drink]\n",
    "col_names = ['All businesses', 'Restaurants', 'Drinks']\n",
    "\n",
    "# Collect all variable names in display order\n",
    "var_order = list(models[0].params.index)\n",
    "\n",
    "# Build rows: coefficient with stars, then SE in parentheses\n",
    "rows = []\n",
    "for var in var_order:\n",
    "    coef_cells = []\n",
    "    se_cells = []\n",
    "    for m in models:\n",
    "        if var in m.params.index:\n",
    "            coef_cells.append(f\"{_fmt(m.params[var])}{_stars(m.pvalues[var])}\")\n",
    "            se_cells.append(f\"({_fmt(m.bse[var])})\")\n",
    "        else:\n",
    "            coef_cells.append('')\n",
    "            se_cells.append('')\n",
    "    rows.append((var, coef_cells, se_cells))\n",
    "\n",
    "# Build LaTeX\n",
    "lines = []\n",
    "lines.append(r\"\\begin{table}[htbp]\")\n",
    "lines.append(r\"\\centering\")\n",
    "lines.append(r\"\\caption{OLS Regression Results: Image Memorability (Study 1)}\")\n",
    "lines.append(r\"\\label{tab:study1_ols}\")\n",
    "lines.append(r\"\\small\")\n",
    "ncols = len(models)\n",
    "lines.append(r\"\\begin{tabular}{l\" + \" c\" * ncols + \"}\")\n",
    "lines.append(r\"\\toprule\")\n",
    "header = \" & \".join([\"\"] + col_names) + r\" \\\\\"\n",
    "lines.append(header)\n",
    "lines.append(r\"\\midrule\")\n",
    "\n",
    "for var, coef_cells, se_cells in rows:\n",
    "    # Clean variable name for LaTeX\n",
    "    var_tex = var.replace('_', r'\\_')\n",
    "    coef_row = \" & \".join([var_tex] + coef_cells) + r\" \\\\\"\n",
    "    se_row = \" & \".join([\"\"] + se_cells) + r\" \\\\\"\n",
    "    lines.append(coef_row)\n",
    "    lines.append(se_row)\n",
    "\n",
    "lines.append(r\"\\midrule\")\n",
    "# N and R-squared\n",
    "n_cells = [f\"{int(m.nobs):,}\" for m in models]\n",
    "r2_cells = [_fmt(m.rsquared, 3) for m in models]\n",
    "r2_adj_cells = [_fmt(m.rsquared_adj, 3) for m in models]\n",
    "lines.append(\" & \".join([\"$N$\"] + n_cells) + r\" \\\\\")\n",
    "lines.append(\" & \".join([\"$R^2$\"] + r2_cells) + r\" \\\\\")\n",
    "lines.append(\" & \".join([\"Adj. $R^2$\"] + r2_adj_cells) + r\" \\\\\")\n",
    "lines.append(r\"\\bottomrule\")\n",
    "lines.append(r\"\\end{tabular}\")\n",
    "lines.append(r\"\\begin{minipage}{\\textwidth}\")\n",
    "lines.append(r\"\\vspace{4pt}\")\n",
    "lines.append(r\"\\footnotesize\")\n",
    "lines.append(r\"\\textit{Note.} Standard errors clustered by business (in parentheses). \"\n",
    "             r\"$^\\dagger p < .10$, $^* p < .05$, $^{**} p < .01$, $^{***} p < .001$.\")\n",
    "lines.append(r\"\\end{minipage}\")\n",
    "lines.append(r\"\\end{table}\")\n",
    "\n",
    "table_tex = \"\\n\".join(lines)\n",
    "print(table_tex)\n",
    "\n",
    "with open('data/output/study1_ols.tex', 'w', encoding='utf-8') as f:\n",
    "    f.write(table_tex)\n",
    "print(\"\\nSaved: data/output/study1_ols.tex\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study 1: Robustness Checks\n",
    "Addressing 4 issues:\n",
    "1. **1. Justify Clustering**: ICC ≈ 0.10–0.12 justifies business-clustered SE.\n",
    "2. **2 (Bounded DV)**: OLS predictions checked within [0,1]; fractional logit robustness.\n",
    "3. **3 Imbalance redundancy**: Conditional composition on people-present subsample.\n",
    "4. **4 Circular hue**: Sin/cos hue parameterization with joint Wald test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Residual ICC (ANOVA decomposition of OLS residuals) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:246: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:259: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:260: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:246: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:259: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:260: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\xuyuhong\\AppData\\Local\\Temp\\ipykernel_75828\\290770572.py:246: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  if p < 0.10:  return '$^\\dagger$'\n",
      "C:\\Users\\xuyuhong\\AppData\\Local\\Temp\\ipykernel_75828\\290770572.py:259: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  lines.append(f'\\caption{{{caption}}}')\n",
      "C:\\Users\\xuyuhong\\AppData\\Local\\Temp\\ipykernel_75828\\290770572.py:260: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  lines.append(f'\\label{{{label}}}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  All businesses: ICC = 0.1186, DEFF = 1.56 (n=154,945, clusters=27,075, avg_cluster_size=5.7)\n",
      "  Restaurants: ICC = 0.0979, DEFF = 1.51 (n=131,624, clusters=21,279, avg_cluster_size=6.2)\n",
      "  Drinks: ICC = 0.0983, DEFF = 1.60 (n=69,548, clusters=9,853, avg_cluster_size=7.1)\n",
      "\n",
      "=== OLS Prediction Bounds Check ===\n",
      "  All businesses: min=0.4623, max=0.9004, all in [0,1]: True\n",
      "  Restaurants: min=0.4607, max=0.8927, all in [0,1]: True\n",
      "  Drinks: min=0.4643, max=0.9080, all in [0,1]: True\n",
      "\n",
      "=== Fractional Logit Robustness (GLM Binomial, business-clustered SE) ===\n",
      "\n",
      "Sign/significance comparison (OLS vs Fractional Logit, All businesses):\n",
      "  food                     : OLS + (p=0.0000) | FracLogit + (p=0.0000) | match: Y\n",
      "  menu                     : OLS + (p=0.0000) | FracLogit + (p=0.0000) | match: Y\n",
      "  inside                   : OLS - (p=0.6503) | FracLogit + (p=0.1567) | match: N\n",
      "  drink                    : OLS + (p=0.0000) | FracLogit + (p=0.0000) | match: Y\n",
      "  average_hue_s            : OLS + (p=0.0000) | FracLogit + (p=0.0000) | match: Y\n",
      "  average_saturation_s     : OLS - (p=0.0000) | FracLogit - (p=0.0000) | match: Y\n",
      "  average_value_s          : OLS + (p=0.0000) | FracLogit + (p=0.0000) | match: Y\n",
      "  person_exist             : OLS + (p=0.0000) | FracLogit + (p=0.0001) | match: Y\n",
      "  var                      : OLS - (p=0.0000) | FracLogit - (p=0.0000) | match: Y\n",
      "  person_total_count       : OLS - (p=0.0000) | FracLogit - (p=0.0000) | match: Y\n",
      "  beauty_score             : OLS + (p=0.0000) | FracLogit + (p=0.0000) | match: Y\n",
      "  sharpness_measure_s      : OLS + (p=0.0000) | FracLogit + (p=0.0003) | match: Y\n",
      "\n",
      "\n",
      "==============================================================\n",
      "                     Frac.Logit I Frac.Logit II Frac.Logit III\n",
      "--------------------------------------------------------------\n",
      "const                0.7726       0.8242        0.6580        \n",
      "                     (0.0256)     (0.0279)      (0.0424)      \n",
      "food                 0.4435       0.4248        0.4588        \n",
      "                     (0.0076)     (0.0085)      (0.0111)      \n",
      "menu                 0.6763       0.6856        0.7510        \n",
      "                     (0.0199)     (0.0215)      (0.0265)      \n",
      "inside               0.0108       -0.0151       0.0420        \n",
      "                     (0.0076)     (0.0091)      (0.0111)      \n",
      "drink                0.7686       0.7429        0.8203        \n",
      "                     (0.0084)     (0.0098)      (0.0115)      \n",
      "average_hue_s        0.0189       0.0125        0.0233        \n",
      "                     (0.0017)     (0.0021)      (0.0025)      \n",
      "average_saturation_s -0.0143      -0.0096       -0.0140       \n",
      "                     (0.0018)     (0.0020)      (0.0023)      \n",
      "average_value_s      0.1019       0.0920        0.1165        \n",
      "                     (0.0019)     (0.0020)      (0.0028)      \n",
      "person_exist         0.0230       0.0054        0.0177        \n",
      "                     (0.0061)     (0.0074)      (0.0100)      \n",
      "var                  -0.0544      -0.0661       -0.0802       \n",
      "                     (0.0081)     (0.0098)      (0.0130)      \n",
      "person_total_count   -0.0193      -0.0188       -0.0179       \n",
      "                     (0.0003)     (0.0004)      (0.0005)      \n",
      "beauty_score         0.0370       0.0285        0.0503        \n",
      "                     (0.0052)     (0.0059)      (0.0091)      \n",
      "sharpness_measure_s  0.0064       0.0074        -0.0006       \n",
      "                     (0.0018)     (0.0018)      (0.0026)      \n",
      "==============================================================\n",
      "Standard errors in parentheses.\n",
      "\n",
      "--- Fractional Logit: Full coefficient table with p-values ---\n",
      "\n",
      "  [All businesses]\n",
      "    const                    : coef=  0.772577  SE=0.025623  p=0.000000\n",
      "    food                     : coef=  0.443476  SE=0.007583  p=0.000000\n",
      "    menu                     : coef=  0.676299  SE=0.019939  p=0.000000\n",
      "    inside                   : coef=  0.010797  SE=0.007623  p=0.156654\n",
      "    drink                    : coef=  0.768582  SE=0.008380  p=0.000000\n",
      "    average_hue_s            : coef=  0.018941  SE=0.001749  p=0.000000\n",
      "    average_saturation_s     : coef= -0.014320  SE=0.001790  p=0.000000\n",
      "    average_value_s          : coef=  0.101931  SE=0.001889  p=0.000000\n",
      "    person_exist             : coef=  0.023046  SE=0.006078  p=0.000150\n",
      "    var                      : coef= -0.054408  SE=0.008053  p=0.000000\n",
      "    person_total_count       : coef= -0.019296  SE=0.000334  p=0.000000\n",
      "    beauty_score             : coef=  0.036999  SE=0.005238  p=0.000000\n",
      "    sharpness_measure_s      : coef=  0.006397  SE=0.001763  p=0.000286\n",
      "\n",
      "  [Restaurants]\n",
      "    const                    : coef=  0.824244  SE=0.027852  p=0.000000\n",
      "    food                     : coef=  0.424832  SE=0.008524  p=0.000000\n",
      "    menu                     : coef=  0.685619  SE=0.021469  p=0.000000\n",
      "    inside                   : coef= -0.015090  SE=0.009088  p=0.096838\n",
      "    drink                    : coef=  0.742886  SE=0.009816  p=0.000000\n",
      "    average_hue_s            : coef=  0.012528  SE=0.002075  p=0.000000\n",
      "    average_saturation_s     : coef= -0.009555  SE=0.001994  p=0.000002\n",
      "    average_value_s          : coef=  0.092007  SE=0.001991  p=0.000000\n",
      "    person_exist             : coef=  0.005386  SE=0.007429  p=0.468430\n",
      "    var                      : coef= -0.066107  SE=0.009789  p=0.000000\n",
      "    person_total_count       : coef= -0.018836  SE=0.000372  p=0.000000\n",
      "    beauty_score             : coef=  0.028459  SE=0.005865  p=0.000001\n",
      "    sharpness_measure_s      : coef=  0.007385  SE=0.001802  p=0.000042\n",
      "\n",
      "  [Drinks]\n",
      "    const                    : coef=  0.658002  SE=0.042387  p=0.000000\n",
      "    food                     : coef=  0.458767  SE=0.011060  p=0.000000\n",
      "    menu                     : coef=  0.751019  SE=0.026525  p=0.000000\n",
      "    inside                   : coef=  0.042006  SE=0.011079  p=0.000150\n",
      "    drink                    : coef=  0.820329  SE=0.011498  p=0.000000\n",
      "    average_hue_s            : coef=  0.023317  SE=0.002504  p=0.000000\n",
      "    average_saturation_s     : coef= -0.013952  SE=0.002274  p=0.000000\n",
      "    average_value_s          : coef=  0.116455  SE=0.002818  p=0.000000\n",
      "    person_exist             : coef=  0.017657  SE=0.010036  p=0.078503\n",
      "    var                      : coef= -0.080157  SE=0.012996  p=0.000000\n",
      "    person_total_count       : coef= -0.017864  SE=0.000493  p=0.000000\n",
      "    beauty_score             : coef=  0.050285  SE=0.009146  p=0.000000\n",
      "    sharpness_measure_s      : coef= -0.000571  SE=0.002612  p=0.826890\n",
      "\n",
      "=== Conditional Composition Robustness (people-present subsample) ===\n",
      "Baseline (full) vs Conditional (people-present) composition coefficient:\n",
      "  All businesses: baseline var=-0.0094 (p=7.334e-09) | conditional var=-0.0093 (p=2.119e-09) | N=51,505, clusters=16,090\n",
      "  Restaurants: baseline var=-0.0117 (p=5.266e-09) | conditional var=-0.0109 (p=8.397e-09) | N=41,596, clusters=12,428\n",
      "  Drinks: baseline var=-0.0153 (p=1.518e-08) | conditional var=-0.0152 (p=1.098e-09) | N=26,183, clusters=6,804\n",
      "\n",
      "\n",
      "===========================================================\n",
      "                     Cond.Comp I Cond.Comp II Cond.Comp III\n",
      "-----------------------------------------------------------\n",
      "const                0.6452      0.6736       0.5980       \n",
      "                     (0.0097)    (0.0116)     (0.0173)     \n",
      "food                 0.0707      0.0696       0.0696       \n",
      "                     (0.0022)    (0.0026)     (0.0031)     \n",
      "menu                 0.1161      0.1180       0.1300       \n",
      "                     (0.0067)    (0.0071)     (0.0103)     \n",
      "inside               0.0038      0.0001       0.0082       \n",
      "                     (0.0023)    (0.0028)     (0.0034)     \n",
      "drink                0.1109      0.1122       0.1195       \n",
      "                     (0.0024)    (0.0029)     (0.0032)     \n",
      "average_hue_s        0.0078      0.0063       0.0074       \n",
      "                     (0.0005)    (0.0007)     (0.0008)     \n",
      "average_saturation_s -0.0012     -0.0001      -0.0001      \n",
      "                     (0.0005)    (0.0006)     (0.0007)     \n",
      "average_value_s      0.0227      0.0217       0.0214       \n",
      "                     (0.0005)    (0.0006)     (0.0008)     \n",
      "var                  -0.0093     -0.0109      -0.0152      \n",
      "                     (0.0016)    (0.0019)     (0.0025)     \n",
      "person_total_count   -0.0038     -0.0036      -0.0038      \n",
      "                     (0.0001)    (0.0001)     (0.0001)     \n",
      "beauty_score         0.0147      0.0082       0.0226       \n",
      "                     (0.0019)    (0.0024)     (0.0035)     \n",
      "sharpness_measure_s  -0.0046     -0.0028      -0.0052      \n",
      "                     (0.0005)    (0.0006)     (0.0008)     \n",
      "R-squared            0.3338      0.3382       0.3231       \n",
      "R-squared Adj.       0.3337      0.3380       0.3228       \n",
      "===========================================================\n",
      "Standard errors in parentheses.\n",
      "\n",
      "--- Conditional Composition: Full coefficient table with p-values ---\n",
      "\n",
      "  [All businesses] (N=51,505)\n",
      "    const                    : coef=  0.645212  SE=0.009678  p=0.000000\n",
      "    food                     : coef=  0.070709  SE=0.002231  p=0.000000\n",
      "    menu                     : coef=  0.116124  SE=0.006741  p=0.000000\n",
      "    inside                   : coef=  0.003771  SE=0.002301  p=0.101176\n",
      "    drink                    : coef=  0.110912  SE=0.002426  p=0.000000\n",
      "    average_hue_s            : coef=  0.007771  SE=0.000534  p=0.000000\n",
      "    average_saturation_s     : coef= -0.001206  SE=0.000540  p=0.025641\n",
      "    average_value_s          : coef=  0.022654  SE=0.000545  p=0.000000\n",
      "    var                      : coef= -0.009292  SE=0.001552  p=0.000000\n",
      "    person_total_count       : coef= -0.003799  SE=0.000091  p=0.000000\n",
      "    beauty_score             : coef=  0.014735  SE=0.001948  p=0.000000\n",
      "    sharpness_measure_s      : coef= -0.004648  SE=0.000532  p=0.000000\n",
      "\n",
      "  [Restaurants] (N=41,596)\n",
      "    const                    : coef=  0.673575  SE=0.011618  p=0.000000\n",
      "    food                     : coef=  0.069635  SE=0.002584  p=0.000000\n",
      "    menu                     : coef=  0.118018  SE=0.007093  p=0.000000\n",
      "    inside                   : coef=  0.000068  SE=0.002827  p=0.980792\n",
      "    drink                    : coef=  0.112181  SE=0.002860  p=0.000000\n",
      "    average_hue_s            : coef=  0.006349  SE=0.000692  p=0.000000\n",
      "    average_saturation_s     : coef= -0.000110  SE=0.000630  p=0.861200\n",
      "    average_value_s          : coef=  0.021731  SE=0.000595  p=0.000000\n",
      "    var                      : coef= -0.010934  SE=0.001898  p=0.000000\n",
      "    person_total_count       : coef= -0.003565  SE=0.000103  p=0.000000\n",
      "    beauty_score             : coef=  0.008197  SE=0.002365  p=0.000529\n",
      "    sharpness_measure_s      : coef= -0.002831  SE=0.000578  p=0.000001\n",
      "\n",
      "  [Drinks] (N=26,183)\n",
      "    const                    : coef=  0.598031  SE=0.017272  p=0.000000\n",
      "    food                     : coef=  0.069639  SE=0.003143  p=0.000000\n",
      "    menu                     : coef=  0.130045  SE=0.010274  p=0.000000\n",
      "    inside                   : coef=  0.008210  SE=0.003364  p=0.014684\n",
      "    drink                    : coef=  0.119491  SE=0.003199  p=0.000000\n",
      "    average_hue_s            : coef=  0.007443  SE=0.000762  p=0.000000\n",
      "    average_saturation_s     : coef= -0.000147  SE=0.000714  p=0.836885\n",
      "    average_value_s          : coef=  0.021366  SE=0.000787  p=0.000000\n",
      "    var                      : coef= -0.015220  SE=0.002497  p=0.000000\n",
      "    person_total_count       : coef= -0.003773  SE=0.000134  p=0.000000\n",
      "    beauty_score             : coef=  0.022561  SE=0.003517  p=0.000000\n",
      "    sharpness_measure_s      : coef= -0.005156  SE=0.000803  p=0.000000\n",
      "\n",
      "=== Circular Hue Robustness (sin/cos parameterization, clustered SE) ===\n",
      "Linear vs Circular hue:\n",
      "  All businesses: linear hue beta=0.0035 (p=9.836e-27) | circular Wald p=5.372e-54 | sin=-0.0123, cos=-0.0038\n",
      "  Restaurants: linear hue beta=0.0023 (p=2.207e-09) | circular Wald p=5.405e-33 | sin=-0.0125, cos=-0.0023\n",
      "  Drinks: linear hue beta=0.0045 (p=2.686e-20) | circular Wald p=1.27e-23 | sin=-0.0097, cos=-0.0053\n",
      "\n",
      "\n",
      "========================================================\n",
      "                     Circ.Hue I Circ.Hue II Circ.Hue III\n",
      "--------------------------------------------------------\n",
      "const                0.6865     0.6974      0.6601      \n",
      "                     (0.0048)   (0.0053)    (0.0082)    \n",
      "food                 0.0865     0.0840      0.0914      \n",
      "                     (0.0015)   (0.0017)    (0.0023)    \n",
      "menu                 0.1185     0.1203      0.1350      \n",
      "                     (0.0031)   (0.0033)    (0.0041)    \n",
      "inside               0.0000     -0.0052     0.0065      \n",
      "                     (0.0016)   (0.0019)    (0.0024)    \n",
      "drink                0.1369     0.1344      0.1476      \n",
      "                     (0.0016)   (0.0018)    (0.0022)    \n",
      "hue_sin              -0.0123    -0.0125     -0.0097     \n",
      "                     (0.0009)   (0.0011)    (0.0012)    \n",
      "hue_cos              -0.0038    -0.0023     -0.0053     \n",
      "                     (0.0006)   (0.0006)    (0.0009)    \n",
      "average_saturation_s -0.0033    -0.0024     -0.0030     \n",
      "                     (0.0003)   (0.0004)    (0.0004)    \n",
      "average_value_s      0.0174     0.0159      0.0202      \n",
      "                     (0.0003)   (0.0004)    (0.0005)    \n",
      "person_exist         0.0048     0.0017      0.0035      \n",
      "                     (0.0012)   (0.0015)    (0.0021)    \n",
      "var                  -0.0102    -0.0123     -0.0158     \n",
      "                     (0.0016)   (0.0020)    (0.0027)    \n",
      "person_total_count   -0.0039    -0.0038     -0.0037     \n",
      "                     (0.0001)   (0.0001)    (0.0001)    \n",
      "beauty_score         0.0084     0.0065      0.0114      \n",
      "                     (0.0010)   (0.0011)    (0.0018)    \n",
      "sharpness_measure_s  0.0021     0.0021      0.0009      \n",
      "                     (0.0003)   (0.0003)    (0.0005)    \n",
      "R-squared            0.3661     0.3650      0.4077      \n",
      "R-squared Adj.       0.3661     0.3649      0.4076      \n",
      "========================================================\n",
      "Standard errors in parentheses.\n",
      "\n",
      "--- Circular Hue: Full coefficient table with p-values ---\n",
      "\n",
      "  [All businesses] Joint Wald F=245.3168, p=5.372e-54\n",
      "    const                    : coef=  0.686544  SE=0.004802  p=0.000000\n",
      "    food                     : coef=  0.086526  SE=0.001530  p=0.000000\n",
      "    menu                     : coef=  0.118462  SE=0.003058  p=0.000000\n",
      "    inside                   : coef=  0.000027  SE=0.001616  p=0.986866\n",
      "    drink                    : coef=  0.136895  SE=0.001575  p=0.000000\n",
      "    hue_sin                  : coef= -0.012303  SE=0.000888  p=0.000000\n",
      "    hue_cos                  : coef= -0.003776  SE=0.000555  p=0.000000\n",
      "    average_saturation_s     : coef= -0.003281  SE=0.000342  p=0.000000\n",
      "    average_value_s          : coef=  0.017427  SE=0.000339  p=0.000000\n",
      "    person_exist             : coef=  0.004814  SE=0.001208  p=0.000068\n",
      "    var                      : coef= -0.010190  SE=0.001623  p=0.000000\n",
      "    person_total_count       : coef= -0.003905  SE=0.000069  p=0.000000\n",
      "    beauty_score             : coef=  0.008407  SE=0.000969  p=0.000000\n",
      "    sharpness_measure_s      : coef=  0.002107  SE=0.000323  p=0.000000\n",
      "\n",
      "  [Restaurants] Joint Wald F=148.5959, p=5.405e-33\n",
      "    const                    : coef=  0.697422  SE=0.005267  p=0.000000\n",
      "    food                     : coef=  0.084019  SE=0.001747  p=0.000000\n",
      "    menu                     : coef=  0.120251  SE=0.003307  p=0.000000\n",
      "    inside                   : coef= -0.005232  SE=0.001937  p=0.006908\n",
      "    drink                    : coef=  0.134403  SE=0.001845  p=0.000000\n",
      "    hue_sin                  : coef= -0.012521  SE=0.001054  p=0.000000\n",
      "    hue_cos                  : coef= -0.002319  SE=0.000644  p=0.000316\n",
      "    average_saturation_s     : coef= -0.002449  SE=0.000374  p=0.000000\n",
      "    average_value_s          : coef=  0.015909  SE=0.000361  p=0.000000\n",
      "    person_exist             : coef=  0.001724  SE=0.001490  p=0.247254\n",
      "    var                      : coef= -0.012326  SE=0.001982  p=0.000000\n",
      "    person_total_count       : coef= -0.003844  SE=0.000077  p=0.000000\n",
      "    beauty_score             : coef=  0.006492  SE=0.001082  p=0.000000\n",
      "    sharpness_measure_s      : coef=  0.002140  SE=0.000330  p=0.000000\n",
      "\n",
      "  [Drinks] Joint Wald F=105.4405, p=1.27e-23\n",
      "    const                    : coef=  0.660102  SE=0.008151  p=0.000000\n",
      "    food                     : coef=  0.091443  SE=0.002251  p=0.000000\n",
      "    menu                     : coef=  0.134982  SE=0.004064  p=0.000000\n",
      "    inside                   : coef=  0.006474  SE=0.002408  p=0.007177\n",
      "    drink                    : coef=  0.147576  SE=0.002236  p=0.000000\n",
      "    hue_sin                  : coef= -0.009694  SE=0.001197  p=0.000000\n",
      "    hue_cos                  : coef= -0.005327  SE=0.000881  p=0.000000\n",
      "    average_saturation_s     : coef= -0.002954  SE=0.000449  p=0.000000\n",
      "    average_value_s          : coef=  0.020182  SE=0.000508  p=0.000000\n",
      "    person_exist             : coef=  0.003510  SE=0.002054  p=0.087568\n",
      "    var                      : coef= -0.015837  SE=0.002699  p=0.000000\n",
      "    person_total_count       : coef= -0.003668  SE=0.000104  p=0.000000\n",
      "    beauty_score             : coef=  0.011423  SE=0.001766  p=0.000000\n",
      "    sharpness_measure_s      : coef=  0.000851  SE=0.000500  p=0.088661\n",
      "\n",
      "=== Hue Origin-Rotation Sensitivity ===\n",
      "Shifting the hue origin by 0-150 degrees and re-fitting linear hue OLS.\n",
      "If the linear coefficient sign flips, it confirms the direction is origin-dependent.\n",
      "\n",
      "  [All businesses]\n",
      "     Shift    Hue coef          SE     p-value   Sign\n",
      "        0deg    0.003514    0.000328    0.000000      +\n",
      "       30deg    0.000523    0.000273    0.055471      +\n",
      "       60deg   -0.002548    0.000280    0.000000      -\n",
      "       90deg   -0.001617    0.000264    0.000000      -\n",
      "      120deg    0.002182    0.000314    0.000000      +\n",
      "      150deg    0.003384    0.000323    0.000000      +\n",
      "    Range: [-0.002548, 0.003514], sign changes: 2\n",
      "\n",
      "  [Restaurants]\n",
      "     Shift    Hue coef          SE     p-value   Sign\n",
      "        0deg    0.002345    0.000392    0.000000      +\n",
      "       30deg    0.000971    0.000297    0.001076      +\n",
      "       60deg   -0.001904    0.000320    0.000000      -\n",
      "       90deg   -0.001803    0.000285    0.000000      -\n",
      "      120deg    0.001433    0.000372    0.000119      +\n",
      "      150deg    0.002249    0.000383    0.000000      +\n",
      "    Range: [-0.001904, 0.002345], sign changes: 2\n",
      "\n",
      "  [Drinks]\n",
      "     Shift    Hue coef          SE     p-value   Sign\n",
      "        0deg    0.004454    0.000482    0.000000      +\n",
      "       30deg   -0.000082    0.000402    0.838833      -\n",
      "       60deg   -0.002918    0.000456    0.000000      -\n",
      "       90deg   -0.001172    0.000385    0.002301      -\n",
      "      120deg    0.002748    0.000517    0.000000      +\n",
      "      150deg    0.004350    0.000486    0.000000      +\n",
      "    Range: [-0.002918, 0.004454], sign changes: 2\n",
      "\n",
      "Saved: data/output/study1_fractional_logit_cluster.tex\n",
      "Saved: data/output/study1_conditional_composition_cluster.tex\n",
      "Saved: data/output/study1_circular_hue_cluster.tex\n",
      "\n",
      "All robustness checks complete.\n"
     ]
    }
   ],
   "source": [
    "# ======================== Study 1 Robustness Checks ========================\n",
    "\n",
    "# --- 1. Residual ICC to justify business-level clustering (ANOVA decomposition) ---\n",
    "print(\"=== Residual ICC (ANOVA decomposition of OLS residuals) ===\")\n",
    "\n",
    "def compute_residual_icc(model, business_ids, sample_name):\n",
    "    \"\"\"\n",
    "    ICC from OLS residuals grouped by business (one-way ANOVA decomposition).\n",
    "    Measures within-business correlation after controlling for covariates.\n",
    "    \"\"\"\n",
    "    resid = model.resid\n",
    "    bid = business_ids.loc[resid.index]\n",
    "    df_r = pd.DataFrame({'bid': bid.values, 'r': resid.values})\n",
    "    groups = df_r.groupby('bid')['r']\n",
    "    k = groups.ngroups\n",
    "    n = len(df_r)\n",
    "    gm = df_r['r'].mean()\n",
    "    g_means = groups.mean()\n",
    "    g_sizes = groups.size()\n",
    "    SSB = ((g_means - gm)**2 * g_sizes).sum()\n",
    "    SSW = groups.apply(lambda x: ((x - x.mean())**2).sum()).sum()\n",
    "    MSB = SSB / (k - 1)\n",
    "    MSW = SSW / (n - k)\n",
    "    n0 = (n - (g_sizes**2).sum() / n) / (k - 1)\n",
    "    icc = (MSB - MSW) / (MSB + (n0 - 1) * MSW)\n",
    "    deff = 1 + (n0 - 1) * icc\n",
    "    print(f\"  {sample_name}: ICC = {icc:.4f}, DEFF = {deff:.2f} \"\n",
    "          f\"(n={n:,}, clusters={k:,}, avg_cluster_size={n0:.1f})\")\n",
    "    return icc\n",
    "\n",
    "icc_all = compute_residual_icc(ols_business, all_df_pic['business_id'], \"All businesses\")\n",
    "icc_res = compute_residual_icc(ols_res, res_df_pic['business_id'], \"Restaurants\")\n",
    "icc_drink = compute_residual_icc(ols_drink, drink_df_pic['business_id'], \"Drinks\")\n",
    "\n",
    "# --- 2. OLS prediction bounds check (Comment 2: bounded DV) ---\n",
    "print(\"\\n=== OLS Prediction Bounds Check ===\")\n",
    "for name, model in [(\"All businesses\", ols_business),\n",
    "                     (\"Restaurants\", ols_res),\n",
    "                     (\"Drinks\", ols_drink)]:\n",
    "    pred = model.fittedvalues\n",
    "    print(f\"  {name}: min={pred.min():.4f}, max={pred.max():.4f}, \"\n",
    "          f\"all in [0,1]: {bool((pred >= 0).all() and (pred <= 1).all())}\")\n",
    "\n",
    "# --- 3. Fractional logit robustness (Comment 2) ---\n",
    "print(\"\\n=== Fractional Logit Robustness (GLM Binomial, business-clustered SE) ===\")\n",
    "\n",
    "def create_fractional_logit(data):\n",
    "    \"\"\"Fractional logit (quasi-MLE) as robustness for bounded [0,1] DV.\"\"\"\n",
    "    df_dummies = pd.get_dummies(data['label'])\n",
    "    df_dummies = df_dummies[['food','menu','inside','drink']].astype(int)\n",
    "    df = pd.concat([data.copy(), df_dummies], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    df['average_hue_s'] = scaler.fit_transform(df[['average_hue']])\n",
    "    df['average_saturation_s'] = scaler.fit_transform(df[['average_saturation']])\n",
    "    df['average_value_s'] = scaler.fit_transform(df[['average_value']])\n",
    "    df['sharpness_measure_s'] = scaler.fit_transform(df[['sharpness_measure']])\n",
    "    X = df[list(df_dummies.columns)+['average_hue_s','average_saturation_s','average_value_s',\n",
    "                                      'person_exist','var',\"person_total_count\",\n",
    "                                      'beauty_score','sharpness_measure_s']]\n",
    "    y = data['memory_score']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial()).fit(\n",
    "        cov_type='cluster', cov_kwds={'groups': data['business_id']})\n",
    "    return model\n",
    "\n",
    "frac_all = create_fractional_logit(all_df_pic)\n",
    "frac_res = create_fractional_logit(res_df_pic)\n",
    "frac_drink = create_fractional_logit(drink_df_pic)\n",
    "\n",
    "# Sign and significance comparison\n",
    "print(\"\\nSign/significance comparison (OLS vs Fractional Logit, All businesses):\")\n",
    "for v in ['food','menu','inside','drink','average_hue_s','average_saturation_s',\n",
    "           'average_value_s','person_exist','var','person_total_count',\n",
    "           'beauty_score','sharpness_measure_s']:\n",
    "    o_s = '+' if ols_business.params[v] > 0 else '-'\n",
    "    f_s = '+' if frac_all.params[v] > 0 else '-'\n",
    "    match = \"Y\" if o_s == f_s else \"N\"\n",
    "    print(f\"  {v:25s}: OLS {o_s} (p={ols_business.pvalues[v]:.4f}) | \"\n",
    "          f\"FracLogit {f_s} (p={frac_all.pvalues[v]:.4f}) | match: {match}\")\n",
    "\n",
    "frac_summary = summary_col([frac_all, frac_res, frac_drink],\n",
    "    model_names=[\"Frac.Logit I\", \"Frac.Logit II\", \"Frac.Logit III\"])\n",
    "print(\"\\n\" + str(frac_summary))\n",
    "\n",
    "# Full p-values for all three fractional logit models\n",
    "print(\"\\n--- Fractional Logit: Full coefficient table with p-values ---\")\n",
    "for name, model in [(\"All businesses\", frac_all), (\"Restaurants\", frac_res), (\"Drinks\", frac_drink)]:\n",
    "    print(f\"\\n  [{name}]\")\n",
    "    for v in model.params.index:\n",
    "        print(f\"    {v:25s}: coef={model.params[v]:10.6f}  SE={model.bse[v]:.6f}  p={model.pvalues[v]:.6f}\")\n",
    "\n",
    "# --- 4. Conditional composition robustness (Comment 3) ---\n",
    "print(\"\\n=== Conditional Composition Robustness (people-present subsample) ===\")\n",
    "\n",
    "def create_conditional_composition_model(data):\n",
    "    \"\"\"Clustered OLS on person_exist==1 subsample; var = conditional imbalance.\"\"\"\n",
    "    df = data[data['person_exist'] == 1].copy()\n",
    "    df_dummies = pd.get_dummies(df['label'])\n",
    "    for col in ['food','menu','inside','drink']:\n",
    "        if col not in df_dummies.columns:\n",
    "            df_dummies[col] = 0\n",
    "    df_dummies = df_dummies[['food','menu','inside','drink']].astype(int)\n",
    "    df = pd.concat([df, df_dummies], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    df['average_hue_s'] = scaler.fit_transform(df[['average_hue']])\n",
    "    df['average_saturation_s'] = scaler.fit_transform(df[['average_saturation']])\n",
    "    df['average_value_s'] = scaler.fit_transform(df[['average_value']])\n",
    "    df['sharpness_measure_s'] = scaler.fit_transform(df[['sharpness_measure']])\n",
    "    # person_exist dropped (constant=1 in this subsample)\n",
    "    X = df[list(df_dummies.columns)+['average_hue_s','average_saturation_s','average_value_s',\n",
    "                                      'var',\"person_total_count\",\n",
    "                                      'beauty_score','sharpness_measure_s']]\n",
    "    y = df['memory_score']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': df['business_id']})\n",
    "    return model, len(df), df['business_id'].nunique()\n",
    "\n",
    "cond_all, n_cond_all, nc_all = create_conditional_composition_model(all_df_pic)\n",
    "cond_res, n_cond_res, nc_res = create_conditional_composition_model(res_df_pic)\n",
    "cond_drink, n_cond_drink, nc_drink = create_conditional_composition_model(drink_df_pic)\n",
    "\n",
    "print(\"Baseline (full) vs Conditional (people-present) composition coefficient:\")\n",
    "for name, base, cond, n_c, nc in [\n",
    "    (\"All businesses\", ols_business, cond_all, n_cond_all, nc_all),\n",
    "    (\"Restaurants\", ols_res, cond_res, n_cond_res, nc_res),\n",
    "    (\"Drinks\", ols_drink, cond_drink, n_cond_drink, nc_drink)]:\n",
    "    print(f\"  {name}: baseline var={base.params['var']:.4f} (p={base.pvalues['var']:.4g}) | \"\n",
    "          f\"conditional var={cond.params['var']:.4f} (p={cond.pvalues['var']:.4g}) | \"\n",
    "          f\"N={n_c:,}, clusters={nc:,}\")\n",
    "\n",
    "cond_summary = summary_col([cond_all, cond_res, cond_drink],\n",
    "    model_names=[\"Cond.Comp I\", \"Cond.Comp II\", \"Cond.Comp III\"])\n",
    "print(\"\\n\" + str(cond_summary))\n",
    "\n",
    "# Full p-values for all three conditional composition models\n",
    "print(\"\\n--- Conditional Composition: Full coefficient table with p-values ---\")\n",
    "for name, model in [(\"All businesses\", cond_all), (\"Restaurants\", cond_res), (\"Drinks\", cond_drink)]:\n",
    "    print(f\"\\n  [{name}] (N={int(model.nobs):,})\")\n",
    "    for v in model.params.index:\n",
    "        print(f\"    {v:25s}: coef={model.params[v]:10.6f}  SE={model.bse[v]:.6f}  p={model.pvalues[v]:.6f}\")\n",
    "\n",
    "# --- 5. Circular hue robustness (Comment 4) ---\n",
    "print(\"\\n=== Circular Hue Robustness (sin/cos parameterization, clustered SE) ===\")\n",
    "\n",
    "def create_circular_hue_model(data):\n",
    "    \"\"\"OLS with sin/cos hue replacing linear hue, business-clustered SE.\"\"\"\n",
    "    df_dummies = pd.get_dummies(data['label'])\n",
    "    df_dummies = df_dummies[['food','menu','inside','drink']].astype(int)\n",
    "    df = pd.concat([data.copy(), df_dummies], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    theta = 2.0 * np.pi * data['average_hue'].values / 180.0  # OpenCV hue period=180\n",
    "    df['hue_sin'] = np.sin(theta)\n",
    "    df['hue_cos'] = np.cos(theta)\n",
    "    df['average_saturation_s'] = scaler.fit_transform(df[['average_saturation']])\n",
    "    df['average_value_s'] = scaler.fit_transform(df[['average_value']])\n",
    "    df['sharpness_measure_s'] = scaler.fit_transform(df[['sharpness_measure']])\n",
    "    X = df[list(df_dummies.columns)+['hue_sin','hue_cos','average_saturation_s',\n",
    "                                      'average_value_s','person_exist','var',\n",
    "                                      \"person_total_count\",'beauty_score',\n",
    "                                      'sharpness_measure_s']]\n",
    "    y = data['memory_score']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': data['business_id']})\n",
    "    wald = model.wald_test(\"hue_sin = 0, hue_cos = 0\", scalar=True)\n",
    "    return model, wald\n",
    "\n",
    "circ_all, wald_all = create_circular_hue_model(all_df_pic)\n",
    "circ_res, wald_res = create_circular_hue_model(res_df_pic)\n",
    "circ_drink, wald_drink = create_circular_hue_model(drink_df_pic)\n",
    "\n",
    "print(\"Linear vs Circular hue:\")\n",
    "for name, base, circ, wald in [\n",
    "    (\"All businesses\", ols_business, circ_all, wald_all),\n",
    "    (\"Restaurants\", ols_res, circ_res, wald_res),\n",
    "    (\"Drinks\", ols_drink, circ_drink, wald_drink)]:\n",
    "    print(f\"  {name}: linear hue beta={base.params['average_hue_s']:.4f} \"\n",
    "          f\"(p={base.pvalues['average_hue_s']:.4g}) | \"\n",
    "          f\"circular Wald p={float(wald.pvalue):.4g} | \"\n",
    "          f\"sin={circ.params['hue_sin']:.4f}, cos={circ.params['hue_cos']:.4f}\")\n",
    "\n",
    "circ_summary = summary_col([circ_all, circ_res, circ_drink],\n",
    "    model_names=[\"Circ.Hue I\", \"Circ.Hue II\", \"Circ.Hue III\"])\n",
    "print(\"\\n\" + str(circ_summary))\n",
    "\n",
    "# Full p-values for all three circular hue models\n",
    "print(\"\\n--- Circular Hue: Full coefficient table with p-values ---\")\n",
    "for name, model, wald in [(\"All businesses\", circ_all, wald_all),\n",
    "                            (\"Restaurants\", circ_res, wald_res),\n",
    "                            (\"Drinks\", circ_drink, wald_drink)]:\n",
    "    print(f\"\\n  [{name}] Joint Wald F={float(wald.statistic):.4f}, p={float(wald.pvalue):.4g}\")\n",
    "    for v in model.params.index:\n",
    "        print(f\"    {v:25s}: coef={model.params[v]:10.6f}  SE={model.bse[v]:.6f}  p={model.pvalues[v]:.6f}\")\n",
    "\n",
    "# --- 5b. Hue origin-rotation sensitivity analysis ---\n",
    "print(\"\\n=== Hue Origin-Rotation Sensitivity ===\")\n",
    "print(\"Shifting the hue origin by 0-150 degrees and re-fitting linear hue OLS.\")\n",
    "print(\"If the linear coefficient sign flips, it confirms the direction is origin-dependent.\\n\")\n",
    "\n",
    "shifts = [0, 30, 60, 90, 120, 150]\n",
    "\n",
    "def fit_rotated_linear_hue(data, shift_deg):\n",
    "    \"\"\"Re-fit clustered OLS with hue origin shifted by shift_deg (mod 180).\"\"\"\n",
    "    df_dummies = pd.get_dummies(data['label'])\n",
    "    df_dummies = df_dummies[['food','menu','inside','drink']].astype(int)\n",
    "    df = pd.concat([data.copy(), df_dummies], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    df['average_hue_rot'] = (data['average_hue'] - shift_deg) % 180.0\n",
    "    df['average_hue_rot_s'] = scaler.fit_transform(df[['average_hue_rot']])\n",
    "    df['average_saturation_s'] = scaler.fit_transform(df[['average_saturation']])\n",
    "    df['average_value_s'] = scaler.fit_transform(df[['average_value']])\n",
    "    df['sharpness_measure_s'] = scaler.fit_transform(df[['sharpness_measure']])\n",
    "    X = df[list(df_dummies.columns)+['average_hue_rot_s','average_saturation_s',\n",
    "                                      'average_value_s','person_exist','var',\n",
    "                                      \"person_total_count\",'beauty_score',\n",
    "                                      'sharpness_measure_s']]\n",
    "    y = data['memory_score']\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': data['business_id']})\n",
    "    return model\n",
    "\n",
    "for name, data in [(\"All businesses\", all_df_pic),\n",
    "                     (\"Restaurants\", res_df_pic),\n",
    "                     (\"Drinks\", drink_df_pic)]:\n",
    "    print(f\"  [{name}]\")\n",
    "    print(f\"    {'Shift':>6s}  {'Hue coef':>10s}  {'SE':>10s}  {'p-value':>10s}  {'Sign':>5s}\")\n",
    "    betas = []\n",
    "    for s in shifts:\n",
    "        m = fit_rotated_linear_hue(data, s)\n",
    "        beta = m.params['average_hue_rot_s']\n",
    "        se = m.bse['average_hue_rot_s']\n",
    "        pv = m.pvalues['average_hue_rot_s']\n",
    "        betas.append(beta)\n",
    "        sign = '+' if beta > 0 else '-'\n",
    "        print(f\"    {s:>5d}deg  {beta:>10.6f}  {se:>10.6f}  {pv:>10.6f}  {sign:>5s}\")\n",
    "    sign_changes = sum(1 for i in range(len(betas)-1)\n",
    "                       if (betas[i] > 0) != (betas[i+1] > 0))\n",
    "    print(f\"    Range: [{min(betas):.6f}, {max(betas):.6f}], sign changes: {sign_changes}\")\n",
    "    print()\n",
    "\n",
    "# --- Save robustness LaTeX tables (custom stars: dagger/*/**/***) ---\n",
    "\n",
    "def _stars(p):\n",
    "    if p < 0.001: return '***'\n",
    "    if p < 0.01:  return '**'\n",
    "    if p < 0.05:  return '*'\n",
    "    if p < 0.10:  return '$^\\dagger$'\n",
    "    return ''\n",
    "\n",
    "def _fmt(val, decimals=4):\n",
    "    return f\"{val:.{decimals}f}\"\n",
    "\n",
    "def save_custom_robustness_tex(models, col_names, filename, caption, label):\n",
    "    \"\"\"Build LaTeX table from model list with custom star convention.\"\"\"\n",
    "    BS = chr(92) + chr(92)  # LaTeX row ending: two backslashes\n",
    "    var_order = list(models[0].params.index)\n",
    "    lines = []\n",
    "    lines.append(r'\\begin{table}[htbp]')\n",
    "    lines.append(r'\\centering')\n",
    "    lines.append(f'\\caption{{{caption}}}')\n",
    "    lines.append(f'\\label{{{label}}}')\n",
    "    lines.append(r'\\small')\n",
    "    lines.append(r'\\begin{tabular}{l' + ' c' * len(models) + '}')\n",
    "    lines.append(r'\\toprule')\n",
    "    lines.append(' & '.join([''] + col_names) + ' ' + BS)\n",
    "    lines.append(r'\\midrule')\n",
    "    for var in var_order:\n",
    "        coef_cells, se_cells = [], []\n",
    "        for m in models:\n",
    "            if var in m.params.index:\n",
    "                coef_cells.append(f'{_fmt(m.params[var])}{_stars(m.pvalues[var])}')\n",
    "                se_cells.append(f'({_fmt(m.bse[var])})')\n",
    "            else:\n",
    "                coef_cells.append('')\n",
    "                se_cells.append('')\n",
    "        var_tex = var.replace('_', r'\\_')\n",
    "        lines.append(' & '.join([var_tex] + coef_cells) + ' ' + BS)\n",
    "        lines.append(' & '.join([''] + se_cells) + ' ' + BS)\n",
    "    lines.append(r'\\midrule')\n",
    "    n_cells = [f'{int(m.nobs):,}' for m in models]\n",
    "    lines.append(' & '.join([r'$N$'] + n_cells) + ' ' + BS)\n",
    "    if hasattr(models[0], 'rsquared'):\n",
    "        r2 = [_fmt(m.rsquared, 3) if hasattr(m, 'rsquared') else '' for m in models]\n",
    "        lines.append(' & '.join([r'$R^2$'] + r2) + ' ' + BS)\n",
    "    lines.append(r'\\bottomrule')\n",
    "    lines.append(r'\\end{tabular}')\n",
    "    lines.append(r'\\begin{minipage}{\\textwidth}')\n",
    "    lines.append(r'\\vspace{4pt}')\n",
    "    lines.append(r'\\footnotesize')\n",
    "    lines.append(r'\\textit{Note.} Standard errors clustered by business (in parentheses). '\n",
    "                 r'$^\\dagger p < .10$, $^* p < .05$, $^{**} p < .01$, $^{***} p < .001$.')\n",
    "    lines.append(r'\\end{minipage}')\n",
    "    lines.append(r'\\end{table}')\n",
    "    table_tex = '\\n'.join(lines)\n",
    "    with open(f'data/output/{filename}', 'w', encoding='utf-8') as f:\n",
    "        f.write(table_tex)\n",
    "    print(f'Saved: data/output/{filename}')\n",
    "\n",
    "save_custom_robustness_tex(\n",
    "    [frac_all, frac_res, frac_drink],\n",
    "    ['All businesses', 'Restaurants', 'Drinks'],\n",
    "    'study1_fractional_logit_cluster.tex',\n",
    "    'Fractional Logit Robustness Check (Study 1)',\n",
    "    'tab:frac_logit')\n",
    "\n",
    "save_custom_robustness_tex(\n",
    "    [cond_all, cond_res, cond_drink],\n",
    "    ['All businesses', 'Restaurants', 'Drinks'],\n",
    "    'study1_conditional_composition_cluster.tex',\n",
    "    'Conditional Composition Robustness: People-Present Subsample (Study 1)',\n",
    "    'tab:cond_comp')\n",
    "\n",
    "save_custom_robustness_tex(\n",
    "    [circ_all, circ_res, circ_drink],\n",
    "    ['All businesses', 'Restaurants', 'Drinks'],\n",
    "    'study1_circular_hue_cluster.tex',\n",
    "    'Circular Hue Decomposition Robustness Check (Study 1)',\n",
    "    'tab:circ_hue')\n",
    "\n",
    "print('\\nAll robustness checks complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others subsample: 10,331 images, 2,969 businesses\n",
      "\n",
      "=== Person Presence Rate by Content Type ===\n",
      "\n",
      "  [All businesses] (N=154,945)\n",
      "         Label   % of sample   person_exist %   n_with_person\n",
      "         drink          8.6%            25.0%           3,335\n",
      "          food         54.7%            17.0%          14,406\n",
      "        inside         27.7%            63.0%          27,070\n",
      "          menu          0.6%            16.0%             160\n",
      "       outside          8.3%            50.7%           6,534\n",
      "       OVERALL        100.0%            33.2%          51,505\n",
      "\n",
      "  [Restaurants] (N=131,624)\n",
      "         Label   % of sample   person_exist %   n_with_person\n",
      "         drink          7.1%            26.6%           2,501\n",
      "          food         59.1%            16.4%          12,781\n",
      "        inside         25.4%            63.1%          21,087\n",
      "          menu          0.7%            16.0%             142\n",
      "       outside          7.7%            50.0%           5,085\n",
      "       OVERALL        100.0%            31.6%          41,596\n",
      "\n",
      "  [Drinks] (N=69,548)\n",
      "         Label   % of sample   person_exist %   n_with_person\n",
      "         drink         13.4%            24.9%           2,319\n",
      "          food         43.9%            17.6%           5,372\n",
      "        inside         33.3%            65.6%          15,182\n",
      "          menu          0.6%            20.0%              81\n",
      "       outside          8.8%            52.8%           3,229\n",
      "       OVERALL        100.0%            37.6%          26,183\n",
      "\n",
      "  [Others (non-rest, non-drink)] (N=10,331)\n",
      "         Label   % of sample   person_exist %   n_with_person\n",
      "         drink          7.6%            24.6%             192\n",
      "          food         39.1%            28.5%           1,151\n",
      "        inside         37.6%            55.3%           2,147\n",
      "          menu          0.5%             8.9%               5\n",
      "       outside         15.2%            54.0%             849\n",
      "       OVERALL        100.0%            42.0%           4,344\n",
      "\n",
      "=== Nested Models: Person Presence Before/After Content Controls ===\n",
      "\n",
      "  Model A = color + sharpness + aesthetics + person_exist + var + total_objects (NO content dummies)\n",
      "  Model B = Model A + content dummies (food, menu, inside, drink)\n",
      "  if coefficient FLIPS SIGN between A and B, person_exist is confounded with content type.\n",
      "\n",
      "  [All businesses] (N=154,945)\n",
      "    Model A (no content):   person_exist = -0.018423 (SE=0.001210, p=0.0000, 95%CI=[-0.020794, -0.016053])\n",
      "    Model B (with content): person_exist = +0.004997 (SE=0.001214, p=0.0000, 95%CI=[0.002617, 0.007376])\n",
      "    >>> SIGN REVERSAL: - -> +, delta = +0.023420\n",
      "\n",
      "  [Restaurants] (N=131,624)\n",
      "    Model A (no content):   person_exist = -0.018890 (SE=0.001414, p=0.0000, 95%CI=[-0.021661, -0.016120])\n",
      "    Model B (with content): person_exist = +0.001833 (SE=0.001501, p=0.2221, 95%CI=[-0.001109, 0.004775])\n",
      "    >>> SIGN REVERSAL: - -> +, delta = +0.020723\n",
      "\n",
      "  [Drinks] (N=69,548)\n",
      "    Model A (no content):   person_exist = -0.020983 (SE=0.001958, p=0.0000, 95%CI=[-0.024819, -0.017146])\n",
      "    Model B (with content): person_exist = +0.003592 (SE=0.002061, p=0.0814, 95%CI=[-0.000449, 0.007632])\n",
      "    >>> SIGN REVERSAL: - -> +, delta = +0.024574\n",
      "\n",
      "  [Others (non-rest, non-drink)] (N=10,331)\n",
      "    Model A (no content):   person_exist = -0.020297 (SE=0.003857, p=0.0000, 95%CI=[-0.027858, -0.012737])\n",
      "    Model B (with content): person_exist = +0.010947 (SE=0.003424, p=0.0014, 95%CI=[0.004235, 0.017659])\n",
      "    >>> SIGN REVERSAL: - -> +, delta = +0.031245\n",
      "\n",
      "=== 95% CI for person_exist in main clustered OLS ===\n",
      "  All businesses: beta=0.0050, 95% CI = [0.0026, 0.0074], p=0.0000\n",
      "  Restaurants: beta=0.0018, 95% CI = [-0.0011, 0.0048], p=0.2221\n",
      "  Drinks: beta=0.0036, 95% CI = [-0.0004, 0.0076], p=0.0814\n",
      "\n",
      "=== Average Memorability by Content Type ===\n",
      "\n",
      "  [All businesses]\n",
      "         drink: mean=0.8309, sd=0.0723, n=13,338\n",
      "          food: mean=0.7883, sd=0.0818, n=84,788\n",
      "        inside: mean=0.6687, sd=0.0997, n=42,935\n",
      "          menu: mean=0.8261, sd=0.0689, n=999\n",
      "       outside: mean=0.6910, sd=0.1027, n=12,885\n",
      "\n",
      "  [Restaurants]\n",
      "         drink: mean=0.8262, sd=0.0742, n=9,397\n",
      "          food: mean=0.7835, sd=0.0810, n=77,784\n",
      "        inside: mean=0.6599, sd=0.0967, n=33,395\n",
      "          menu: mean=0.8277, sd=0.0682, n=886\n",
      "       outside: mean=0.6885, sd=0.1034, n=10,162\n",
      "\n",
      "  [Drinks]\n",
      "         drink: mean=0.8317, sd=0.0710, n=9,329\n",
      "          food: mean=0.7824, sd=0.0832, n=30,557\n",
      "        inside: mean=0.6627, sd=0.0990, n=23,140\n",
      "          menu: mean=0.8247, sd=0.0726, n=405\n",
      "       outside: mean=0.6769, sd=0.1006, n=6,117\n",
      "\n",
      "  [Others]\n",
      "         drink: mean=0.8423, sd=0.0656, n=780\n",
      "          food: mean=0.8458, sd=0.0739, n=4,041\n",
      "        inside: mean=0.7231, sd=0.0996, n=3,882\n",
      "          menu: mean=0.8300, sd=0.0657, n=56\n",
      "       outside: mean=0.7111, sd=0.1021, n=1,572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================== People's Presence: Paradox & \"Others\" Category ========================\n",
    "\n",
    "# --- 6a. Create \"Others\" subsample (non-restaurant, non-drink businesses) ---\n",
    "other_bids = set(all_df_pic['business_id'].unique()) - set(res_df_pic['business_id'].unique()) - set(drink_df_pic['business_id'].unique())\n",
    "other_df_pic = all_df_pic[all_df_pic['business_id'].isin(other_bids)].copy()\n",
    "print(f\"Others subsample: {len(other_df_pic):,} images, {len(other_bids):,} businesses\\n\")\n",
    "\n",
    "# --- 6b. Crosstab: person_exist rate by content type ---\n",
    "print(\"=== Person Presence Rate by Content Type ===\\n\")\n",
    "\n",
    "for name, data in [(\"All businesses\", all_df_pic),\n",
    "                     (\"Restaurants\", res_df_pic),\n",
    "                     (\"Drinks\", drink_df_pic),\n",
    "                     (\"Others (non-rest, non-drink)\", other_df_pic)]:\n",
    "    ct = data.groupby('label')['person_exist'].agg(['mean', 'sum', 'count'])\n",
    "    ct.columns = ['person_rate', 'n_with_person', 'n_total']\n",
    "    ct['pct_of_sample'] = (ct['n_total'] / ct['n_total'].sum() * 100).round(1)\n",
    "    ct['person_rate'] = (ct['person_rate'] * 100).round(1)\n",
    "    print(f\"  [{name}] (N={len(data):,})\")\n",
    "    print(f\"    {'Label':>10s}  {'% of sample':>12s}  {'person_exist %':>15s}  {'n_with_person':>14s}\")\n",
    "    for label, row in ct.iterrows():\n",
    "        print(f\"    {label:>10s}  {row['pct_of_sample']:>11.1f}%  {row['person_rate']:>14.1f}%  {int(row['n_with_person']):>14,}\")\n",
    "    # Overall person_exist rate\n",
    "    overall_rate = data['person_exist'].mean() * 100\n",
    "    print(f\"    {'OVERALL':>10s}  {'100.0':>11s}%  {overall_rate:>14.1f}%  {int(data['person_exist'].sum()):>14,}\")\n",
    "    print()\n",
    "\n",
    "# --- 6c. Nested models: person_exist BEFORE vs AFTER content controls ---\n",
    "print(\"=== Nested Models: Person Presence Before/After Content Controls ===\\n\")\n",
    "print(\"  Model A = color + sharpness + aesthetics + person_exist + var + total_objects (NO content dummies)\")\n",
    "print(\"  Model B = Model A + content dummies (food, menu, inside, drink)\")\n",
    "print(\"  if coefficient FLIPS SIGN between A and B, person_exist is confounded with content type.\\n\")\n",
    "\n",
    "def fit_nested_models(data, sample_name):\n",
    "    \"\"\"\n",
    "    Model A: WITHOUT content dummies → captures total (confounded) effect\n",
    "    Model B: WITH content dummies    → captures conditional (partial) effect\n",
    "    Sign reversal: person_exist covaries with a content type\n",
    "    that has opposite memorability association.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    df_dummies = pd.get_dummies(df['label'])\n",
    "    for col in ['food','menu','inside','drink']:\n",
    "        if col not in df_dummies.columns:\n",
    "            df_dummies[col] = 0\n",
    "    df_dummies = df_dummies[['food','menu','inside','drink']].astype(int)\n",
    "    df = pd.concat([df, df_dummies], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    df['average_hue_s'] = scaler.fit_transform(df[['average_hue']])\n",
    "    df['average_saturation_s'] = scaler.fit_transform(df[['average_saturation']])\n",
    "    df['average_value_s'] = scaler.fit_transform(df[['average_value']])\n",
    "    df['sharpness_measure_s'] = scaler.fit_transform(df[['sharpness_measure']])\n",
    "    y = df['memory_score']\n",
    "    groups = df['business_id']\n",
    "\n",
    "    # Model A: WITHOUT content dummies\n",
    "    X_a = df[['average_hue_s','average_saturation_s','average_value_s',\n",
    "              'person_exist','var','person_total_count',\n",
    "              'beauty_score','sharpness_measure_s']]\n",
    "    X_a = sm.add_constant(X_a)\n",
    "    model_a = sm.OLS(y, X_a).fit(cov_type='cluster', cov_kwds={'groups': groups})\n",
    "\n",
    "    # Model B: WITH content dummies (same as main model)\n",
    "    X_b = df[['food','menu','inside','drink',\n",
    "              'average_hue_s','average_saturation_s','average_value_s',\n",
    "              'person_exist','var','person_total_count',\n",
    "              'beauty_score','sharpness_measure_s']]\n",
    "    X_b = sm.add_constant(X_b)\n",
    "    model_b = sm.OLS(y, X_b).fit(cov_type='cluster', cov_kwds={'groups': groups})\n",
    "\n",
    "    # Extract person_exist results\n",
    "    pe_a = {'coef': model_a.params['person_exist'], 'se': model_a.bse['person_exist'],\n",
    "            'p': model_a.pvalues['person_exist'], 'ci_lo': model_a.conf_int().loc['person_exist', 0],\n",
    "            'ci_hi': model_a.conf_int().loc['person_exist', 1]}\n",
    "    pe_b = {'coef': model_b.params['person_exist'], 'se': model_b.bse['person_exist'],\n",
    "            'p': model_b.pvalues['person_exist'], 'ci_lo': model_b.conf_int().loc['person_exist', 0],\n",
    "            'ci_hi': model_b.conf_int().loc['person_exist', 1]}\n",
    "\n",
    "    sign_a = '+' if pe_a['coef'] > 0 else '-'\n",
    "    sign_b = '+' if pe_b['coef'] > 0 else '-'\n",
    "    reversal = \"SIGN REVERSAL\" if sign_a != sign_b else \"same sign\"\n",
    "\n",
    "    print(f\"  [{sample_name}] (N={int(model_a.nobs):,})\")\n",
    "    print(f\"    Model A (no content):   person_exist = {pe_a['coef']:+.6f} \"\n",
    "          f\"(SE={pe_a['se']:.6f}, p={pe_a['p']:.4f}, 95%CI=[{pe_a['ci_lo']:.6f}, {pe_a['ci_hi']:.6f}])\")\n",
    "    print(f\"    Model B (with content): person_exist = {pe_b['coef']:+.6f} \"\n",
    "          f\"(SE={pe_b['se']:.6f}, p={pe_b['p']:.4f}, 95%CI=[{pe_b['ci_lo']:.6f}, {pe_b['ci_hi']:.6f}])\")\n",
    "    print(f\"    >>> {reversal}: {sign_a} -> {sign_b}, \"\n",
    "          f\"delta = {pe_b['coef'] - pe_a['coef']:+.6f}\")\n",
    "    print()\n",
    "    return model_a, model_b\n",
    "\n",
    "# Run for all four samples\n",
    "nested_a_all, nested_b_all = fit_nested_models(all_df_pic, \"All businesses\")\n",
    "nested_a_res, nested_b_res = fit_nested_models(res_df_pic, \"Restaurants\")\n",
    "nested_a_drink, nested_b_drink = fit_nested_models(drink_df_pic, \"Drinks\")\n",
    "nested_a_other, nested_b_other = fit_nested_models(other_df_pic, \"Others (non-rest, non-drink)\")\n",
    "\n",
    "# --- 6d. Main model 95% CIs for person_exist ---\n",
    "print(\"=== 95% CI for person_exist in main clustered OLS ===\")\n",
    "for name, model in [(\"All businesses\", ols_business),\n",
    "                     (\"Restaurants\", ols_res),\n",
    "                     (\"Drinks\", ols_drink)]:\n",
    "    ci = model.conf_int().loc['person_exist']\n",
    "    print(f\"  {name}: beta={model.params['person_exist']:.4f}, \"\n",
    "          f\"95% CI = [{ci[0]:.4f}, {ci[1]:.4f}], p={model.pvalues['person_exist']:.4f}\")\n",
    "\n",
    "# --- 6e. Content-type memorability: are inside shots less memorable? ---\n",
    "print(\"\\n=== Average Memorability by Content Type ===\\n\")\n",
    "for name, data in [(\"All businesses\", all_df_pic),\n",
    "                     (\"Restaurants\", res_df_pic),\n",
    "                     (\"Drinks\", drink_df_pic),\n",
    "                     (\"Others\", other_df_pic)]:\n",
    "    ct = data.groupby('label')['memory_score'].agg(['mean', 'std', 'count'])\n",
    "    print(f\"  [{name}]\")\n",
    "    for label, row in ct.iterrows():\n",
    "        print(f\"    {label:>10s}: mean={row['mean']:.4f}, sd={row['std']:.4f}, n={int(row['count']):,}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Person Presence Rates and Average Memorability by Image Content Type}\n",
      "\\label{tab:person_content_crosstab}\n",
      "\\small\n",
      "\\begin{tabular}{l r r r r r}\n",
      "\\toprule\n",
      "Content type & $N$ & \\% of sample & Person present (\\%) & Mean memorability & (SD) \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textit{Panel A: All businesses}} \\\\\n",
      "\\midrule\n",
      "  Food       & 84,788 & 54.7\\% & 17.0\\% & 0.788 & (0.082) \\\\\n",
      "  Inside     & 42,935 & 27.7\\% & 63.0\\% & 0.669 & (0.100) \\\\\n",
      "  Drink      & 13,338 & 8.6\\% & 25.0\\% & 0.831 & (0.072) \\\\\n",
      "  Outside    & 12,885 & 8.3\\% & 50.7\\% & 0.691 & (0.103) \\\\\n",
      "  Menu       & 999 & 0.6\\% & 16.0\\% & 0.826 & (0.069) \\\\\n",
      "  \\midrule\n",
      "  Overall    & 154,945 & 100.0\\% & 33.2\\% & 0.751 & (0.106) \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textit{Panel B: Restaurants}} \\\\\n",
      "\\midrule\n",
      "  Food       & 77,784 & 59.1\\% & 16.4\\% & 0.784 & (0.081) \\\\\n",
      "  Inside     & 33,395 & 25.4\\% & 63.1\\% & 0.660 & (0.097) \\\\\n",
      "  Drink      & 9,397 & 7.1\\% & 26.6\\% & 0.826 & (0.074) \\\\\n",
      "  Outside    & 10,162 & 7.7\\% & 50.0\\% & 0.689 & (0.103) \\\\\n",
      "  Menu       & 886 & 0.7\\% & 16.0\\% & 0.828 & (0.068) \\\\\n",
      "  \\midrule\n",
      "  Overall    & 131,624 & 100.0\\% & 31.6\\% & 0.748 & (0.105) \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textit{Panel C: Drink-related}} \\\\\n",
      "\\midrule\n",
      "  Food       & 30,557 & 43.9\\% & 17.6\\% & 0.782 & (0.083) \\\\\n",
      "  Inside     & 23,140 & 33.3\\% & 65.6\\% & 0.663 & (0.099) \\\\\n",
      "  Drink      & 9,329 & 13.4\\% & 24.9\\% & 0.832 & (0.071) \\\\\n",
      "  Outside    & 6,117 & 8.8\\% & 52.8\\% & 0.677 & (0.101) \\\\\n",
      "  Menu       & 405 & 0.6\\% & 20.0\\% & 0.825 & (0.073) \\\\\n",
      "  \\midrule\n",
      "  Overall    & 69,548 & 100.0\\% & 37.6\\% & 0.740 & (0.110) \\\\\n",
      "\\midrule\n",
      "\\multicolumn{6}{l}{\\textit{Panel D: Other businesses}} \\\\\n",
      "\\midrule\n",
      "  Food       & 4,041 & 39.1\\% & 28.5\\% & 0.846 & (0.074) \\\\\n",
      "  Inside     & 3,882 & 37.6\\% & 55.3\\% & 0.723 & (0.100) \\\\\n",
      "  Drink      & 780 & 7.6\\% & 24.6\\% & 0.842 & (0.066) \\\\\n",
      "  Outside    & 1,572 & 15.2\\% & 54.0\\% & 0.711 & (0.102) \\\\\n",
      "  Menu       & 56 & 0.5\\% & 8.9\\% & 0.830 & (0.066) \\\\\n",
      "  \\midrule\n",
      "  Overall    & 10,331 & 100.0\\% & 42.0\\% & 0.779 & (0.108) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{minipage}{\\textwidth}\n",
      "\\vspace{4pt}\n",
      "\\footnotesize\n",
      "\\textit{Note.} Each panel reports one subsample. ``Person present'' is the percentage of images\n",
      "in that content category containing at least one YOLO-detected person. ``Other businesses'' are establishments outside\n",
      "the restaurant and drink categories (retail, services, entertainment, etc.). People appear\n",
      "disproportionately in interior shots across all subsamples, and inside images\n",
      "carry the lowest average memorability (sede figure 2).\n",
      "\\end{minipage}\n",
      "\\end{table}\n",
      "\n",
      "Saved: data/output/supplementary_table_person_content.tex\n",
      "\n",
      "\\begin{table}[htbp]\n",
      "\\centering\n",
      "\\caption{Person Presence--Memorability Relationship: Nested Model Comparison}\n",
      "\\label{tab:nested_person}\n",
      "\\small\n",
      "\\begin{tabular}{l r r r r r r r}\n",
      "\\toprule\n",
      " & & & \\multicolumn{2}{c}{Model A} & \\multicolumn{2}{c}{Model B} & \\\\\n",
      "\\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
      "Sample & $N$ & Clusters & $\\hat{\\beta}$ & (SE) & $\\hat{\\beta}$ & (SE) & $\\Delta\\hat{\\beta}$ \\\\\n",
      "\\midrule\n",
      "  All businesses & 154,945 & 27,075 & -0.0184*** & (0.0012) & 0.0050*** & (0.0012) & +0.0234 \\\\\n",
      "  Restaurants & 131,624 & 21,279 & -0.0189*** & (0.0014) & 0.0018 & (0.0015) & +0.0207 \\\\\n",
      "  Drink-related & 69,548 & 9,853 & -0.0210*** & (0.0020) & 0.0036$^\\dagger$ & (0.0021) & +0.0246 \\\\\n",
      "  Other businesses & 10,331 & 2,969 & -0.0203*** & (0.0039) & 0.0109** & (0.0034) & +0.0312 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{minipage}{\\textwidth}\n",
      "\\vspace{4pt}\n",
      "\\footnotesize\n",
      "\\textit{Note.} Model~A regresses image memorability on colour properties (hue, saturation,\n",
      "brightness), sharpness, aesthetic quality, person presence, people--object imbalance,\n",
      "and total object count, \\textit{without} content-category indicators. Model~B adds four\n",
      "content-type dummies (food, menu, inside, drink; outside is the reference category).\n",
      "Both models use OLS with standard errors clustered at the business level.\n",
      "$\\Delta\\hat{\\beta} = \\hat{\\beta}_B - \\hat{\\beta}_A$ captures the change in the\n",
      "person-presence coefficient when content type is controlled. The sign reversal from\n",
      "negative (Model~A) to positive (Model~B) across all four subsamples constitutes a paradox: images containing people are disproportionately interior shots,\n",
      "which have lower memorability, so the unconditional association is negative. Once\n",
      "content type is controlled, person presence is associated with modestly\n",
      "\\textit{higher} memorability. The conditional effect is largest for non-restaurant,\n",
      "non-drink businesses, where human figures are less routine and more visually distinctive.\n",
      "$^\\dagger p < .10$, $^* p < .05$, $^{**} p < .01$, $^{***} p < .001$.\n",
      "\\end{minipage}\n",
      "\\end{table}\n",
      "\n",
      "Saved: data/output/supplementary_table_nested_person.tex\n"
     ]
    }
   ],
   "source": [
    "# ======================== Supplementary LaTeX Tables for study 1 results ========================\n",
    "\n",
    "# ---------- Person Presence & Memorability by Content Type ----------\n",
    "\n",
    "def build_panel_a(data, panel_label):\n",
    "    \"\"\"Build rows for one panel (one subsample).\"\"\"\n",
    "    rows = []\n",
    "    ct = data.groupby('label').agg(\n",
    "        n_total=('memory_score', 'count'),\n",
    "        person_rate=('person_exist', 'mean'),\n",
    "        mem_mean=('memory_score', 'mean'),\n",
    "        mem_sd=('memory_score', 'std')\n",
    "    )\n",
    "    total_n = ct['n_total'].sum()\n",
    "    for label in ['food', 'inside', 'drink', 'outside', 'menu']:\n",
    "        if label not in ct.index:\n",
    "            continue\n",
    "        r = ct.loc[label]\n",
    "        pct_sample = r['n_total'] / total_n * 100\n",
    "        rows.append(\n",
    "            f\"  {label.capitalize():10s} & {int(r['n_total']):,} & {pct_sample:.1f}\\\\% \"\n",
    "            f\"& {r['person_rate']*100:.1f}\\\\% & {r['mem_mean']:.3f} & ({r['mem_sd']:.3f}) \\\\\\\\\"\n",
    "        )\n",
    "    # Overall row\n",
    "    overall_person = data['person_exist'].mean() * 100\n",
    "    overall_mem = data['memory_score'].mean()\n",
    "    overall_sd = data['memory_score'].std()\n",
    "    rows.append(f\"  \\\\midrule\")\n",
    "    rows.append(\n",
    "        f\"  Overall    & {len(data):,} & 100.0\\\\% \"\n",
    "        f\"& {overall_person:.1f}\\\\% & {overall_mem:.3f} & ({overall_sd:.3f}) \\\\\\\\\"\n",
    "    )\n",
    "    header = f\"\\\\midrule\\n\\\\multicolumn{{6}}{{l}}{{\\\\textit{{Panel {panel_label}}}}} \\\\\\\\\\n\\\\midrule\"\n",
    "    return header + \"\\n\" + \"\\n\".join(rows)\n",
    "\n",
    "panels_a = {\n",
    "    'A: All businesses': all_df_pic,\n",
    "    'B: Restaurants': res_df_pic,\n",
    "    'C: Drink-related': drink_df_pic,\n",
    "    'D: Other businesses': other_df_pic,\n",
    "}\n",
    "\n",
    "table_a_body = \"\\n\".join(build_panel_a(data, label) for label, data in panels_a.items())\n",
    "\n",
    "table_a = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Person Presence Rates and Average Memorability by Image Content Type}\n",
    "\\label{tab:person_content_crosstab}\n",
    "\\small\n",
    "\\begin{tabular}{l r r r r r}\n",
    "\\toprule\n",
    "Content type & $N$ & \\% of sample & Person present (\\%) & Mean memorability & (SD) \\\\\n",
    "\"\"\" + table_a_body + r\"\"\"\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\begin{minipage}{\\textwidth}\n",
    "\\vspace{4pt}\n",
    "\\footnotesize\n",
    "\\textit{Note.} Each panel reports one subsample. ``Person present'' is the percentage of images\n",
    "in that content category containing at least one YOLO-detected person. ``Other businesses'' are establishments outside\n",
    "the restaurant and drink categories (retail, services, entertainment, etc.). People appear\n",
    "disproportionately in interior shots across all subsamples, and inside images\n",
    "carry the lowest average memorability (sede figure 2).\n",
    "\\end{minipage}\n",
    "\\end{table}\"\"\"\n",
    "\n",
    "print(table_a)\n",
    "\n",
    "with open('data/output/supplementary_table_person_content.tex', 'w', encoding='utf-8') as f:\n",
    "    f.write(table_a)\n",
    "print(\"\\nSaved: data/output/supplementary_table_person_content.tex\")\n",
    "\n",
    "# ---------- Nested Model Comparison  ----------\n",
    "\n",
    "def build_nested_row(data, sample_label):\n",
    "    \"\"\"Fit Model A (no content) and Model B (with content), return LaTeX row.\"\"\"\n",
    "    df = data.copy()\n",
    "    df_dummies = pd.get_dummies(df['label'])\n",
    "    for col in ['food','menu','inside','drink']:\n",
    "        if col not in df_dummies.columns:\n",
    "            df_dummies[col] = 0\n",
    "    df_dummies = df_dummies[['food','menu','inside','drink']].astype(int)\n",
    "    df = pd.concat([df, df_dummies], axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    df['average_hue_s'] = scaler.fit_transform(df[['average_hue']])\n",
    "    df['average_saturation_s'] = scaler.fit_transform(df[['average_saturation']])\n",
    "    df['average_value_s'] = scaler.fit_transform(df[['average_value']])\n",
    "    df['sharpness_measure_s'] = scaler.fit_transform(df[['sharpness_measure']])\n",
    "    y = df['memory_score']\n",
    "    groups = df['business_id']\n",
    "\n",
    "    # Model A: no content dummies\n",
    "    X_a = sm.add_constant(df[['average_hue_s','average_saturation_s','average_value_s',\n",
    "              'person_exist','var','person_total_count','beauty_score','sharpness_measure_s']])\n",
    "    model_a = sm.OLS(y, X_a).fit(cov_type='cluster', cov_kwds={'groups': groups})\n",
    "\n",
    "    # Model B: with content dummies\n",
    "    X_b = sm.add_constant(df[['food','menu','inside','drink',\n",
    "              'average_hue_s','average_saturation_s','average_value_s',\n",
    "              'person_exist','var','person_total_count','beauty_score','sharpness_measure_s']])\n",
    "    model_b = sm.OLS(y, X_b).fit(cov_type='cluster', cov_kwds={'groups': groups})\n",
    "\n",
    "    a_coef = model_a.params['person_exist']\n",
    "    a_se = model_a.bse['person_exist']\n",
    "    a_p = model_a.pvalues['person_exist']\n",
    "    b_coef = model_b.params['person_exist']\n",
    "    b_se = model_b.bse['person_exist']\n",
    "    b_p = model_b.pvalues['person_exist']\n",
    "    delta = b_coef - a_coef\n",
    "\n",
    "    def stars(p):\n",
    "        if p < 0.001: return '***'\n",
    "        if p < 0.01: return '**'\n",
    "        if p < 0.05: return '*'\n",
    "        if p < 0.10: return '$^\\\\dagger$'\n",
    "        return ''\n",
    "\n",
    "    n_obs = int(model_a.nobs)\n",
    "    n_clust = df['business_id'].nunique()\n",
    "\n",
    "    row = (f\"  {sample_label} & {n_obs:,} & {n_clust:,} \"\n",
    "           f\"& {a_coef:.4f}{stars(a_p)} & ({a_se:.4f}) \"\n",
    "           f\"& {b_coef:.4f}{stars(b_p)} & ({b_se:.4f}) \"\n",
    "           f\"& {delta:+.4f} \\\\\\\\\")\n",
    "    return row\n",
    "\n",
    "nested_rows = []\n",
    "for label, data in [(\"All businesses\", all_df_pic),\n",
    "                     (\"Restaurants\", res_df_pic),\n",
    "                     (\"Drink-related\", drink_df_pic),\n",
    "                     (\"Other businesses\", other_df_pic)]:\n",
    "    nested_rows.append(build_nested_row(data, label))\n",
    "\n",
    "table_b = r\"\"\"\\begin{table}[htbp]\n",
    "\\centering\n",
    "\\caption{Person Presence--Memorability Relationship: Nested Model Comparison}\n",
    "\\label{tab:nested_person}\n",
    "\\small\n",
    "\\begin{tabular}{l r r r r r r r}\n",
    "\\toprule\n",
    " & & & \\multicolumn{2}{c}{Model A} & \\multicolumn{2}{c}{Model B} & \\\\\n",
    "\\cmidrule(lr){4-5} \\cmidrule(lr){6-7}\n",
    "Sample & $N$ & Clusters & $\\hat{\\beta}$ & (SE) & $\\hat{\\beta}$ & (SE) & $\\Delta\\hat{\\beta}$ \\\\\n",
    "\\midrule\n",
    "\"\"\" + \"\\n\".join(nested_rows) + r\"\"\"\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "\\begin{minipage}{\\textwidth}\n",
    "\\vspace{4pt}\n",
    "\\footnotesize\n",
    "\\textit{Note.} Model~A regresses image memorability on colour properties (hue, saturation,\n",
    "brightness), sharpness, aesthetic quality, person presence, people--object imbalance,\n",
    "and total object count, \\textit{without} content-category indicators. Model~B adds four\n",
    "content-type dummies (food, menu, inside, drink; outside is the reference category).\n",
    "Both models use OLS with standard errors clustered at the business level.\n",
    "$\\Delta\\hat{\\beta} = \\hat{\\beta}_B - \\hat{\\beta}_A$ captures the change in the\n",
    "person-presence coefficient when content type is controlled. The sign reversal from\n",
    "negative (Model~A) to positive (Model~B) across all four subsamples constitutes a paradox: images containing people are disproportionately interior shots,\n",
    "which have lower memorability, so the unconditional association is negative. Once\n",
    "content type is controlled, person presence is associated with modestly\n",
    "\\textit{higher} memorability. The conditional effect is largest for non-restaurant,\n",
    "non-drink businesses, where human figures are less routine and more visually distinctive.\n",
    "$^\\dagger p < .10$, $^* p < .05$, $^{**} p < .01$, $^{***} p < .001$.\n",
    "\\end{minipage}\n",
    "\\end{table}\"\"\"\n",
    "\n",
    "print(\"\\n\" + table_b)\n",
    "\n",
    "with open('data/output/supplementary_table_nested_person.tex', 'w', encoding='utf-8') as f:\n",
    "    f.write(table_b)\n",
    "print(\"\\nSaved: data/output/supplementary_table_nested_person.tex\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tthDdfc2uhl_"
   },
   "source": [
    "# study 2: Memorability- business ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data process\n",
    "def contains_one(lst):\n",
    "    return 1 if 1 in lst else 0\n",
    "\n",
    "\n",
    "def bus_pic_data_process(business_df,pic_df):\n",
    "    scaler = StandardScaler()\n",
    "    business_id_unique = business_df['business_id'].unique().tolist()\n",
    "    count = 0\n",
    "    pic_bus_df = []\n",
    "    for business_id in business_id_unique[:]:\n",
    "        count+=1\n",
    "        single_bus = pic_df[pic_df['business_id']==business_id]\n",
    "        food_rate = round(len(single_bus[single_bus['label']=='food'])/len(single_bus),3)\n",
    "        drink_rate = round(len(single_bus[single_bus['label']=='drink'])/len(single_bus),3)\n",
    "        menu_rate = round(len(single_bus[single_bus['label']=='menu'])/len(single_bus),3)\n",
    "        inside_rate = round(len(single_bus[single_bus['label']=='inside'])/len(single_bus),3)\n",
    "        outside_rate = round(len(single_bus[single_bus['label']=='outside'])/len(single_bus),3)\n",
    "        person_exist = contains_one(single_bus['person_exist'].values.tolist())\n",
    "        # person percentage\n",
    "        try:\n",
    "            person_percentage = single_bus['person_exist'].sum()/len(single_bus)\n",
    "        except:\n",
    "            person_percentage = 0\n",
    "        avg_var = round(single_bus['var'].mean(),3)\n",
    "        person_total_count = round(single_bus['person_total_count'].mean(),3)\n",
    "        person_count = round(single_bus['person_count'].mean(),3)\n",
    "        pic_bus_df.append([business_id,food_rate,drink_rate,menu_rate,inside_rate,outside_rate,avg_var,person_exist,person_percentage,person_total_count, person_count])\n",
    "    pic_bus_df = pd.DataFrame(pic_bus_df,columns=['business_id','food','drink','menu','inside','outside','var','person_exist',\"person_percentage\",'person_total_count','person_count'])\n",
    "    bus_data = business_df\n",
    "    # # data merge\n",
    "    res = pd.merge(bus_data,pic_bus_df,on='business_id')\n",
    "    return res\n",
    "business_df = bus_pic_data_process(business_df,all_df_pic)\n",
    "business_res = bus_pic_data_process(business_res,res_df_pic)\n",
    "business_drink = bus_pic_data_process(business_drink,drink_df_pic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747915654042,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "Sd3a-84Xburv"
   },
   "outputs": [],
   "source": [
    "# business 均值和标准差的统计\n",
    "def bus_result_mean(data):\n",
    "    res = [\n",
    "    round(len(data[data['stars']==1.0])/len(data),3),\n",
    "    round(len(data[data['stars']==1.5])/len(data),3),\n",
    "    round(len(data[data['stars']==2.0])/len(data),3),\n",
    "    round(len(data[data['stars']==2.5])/len(data),3),\n",
    "    round(len(data[data['stars']==3.0])/len(data),3),\n",
    "    round(len(data[data['stars']==3.5])/len(data),3),\n",
    "    round(len(data[data['stars']==4.0])/len(data),3),\n",
    "    round(len(data[data['stars']==4.5])/len(data),3),\n",
    "    round(len(data[data['stars']==5.0])/len(data),3),\n",
    "    round(data['star_avg'].mean(),3),\n",
    "    round(data['memory_score'].mean(),3),\n",
    "    round(data['review_count'].mean(),3),\n",
    "    round(data['photo_count'].mean(),3),\n",
    "    round(data['categories_counts'].mean(),3),\n",
    "    round(data['star_std'].mean(),3),\n",
    "    round(data['contents_score_avg'].mean(),3),\n",
    "    # round(data['useful_avg'].mean(),3),\n",
    "    # round(data['funny_avg'].mean(),3),\n",
    "    # round(data['cool_avg'].mean(),3),\n",
    "    # round(data['person_count'].mean(), 3),\n",
    "    round(data['beauty_score'].mean(),3),\n",
    "    round(data['sharpness_measure'].mean(),3),\n",
    "    round(data['average_hue'].mean(), 3),\n",
    "    round(data['average_saturation'].mean(),3),\n",
    "    round(data['average_value'].mean(),3),\n",
    "    round(data['person_total_count_x'].mean(),3),\n",
    "    round(len(data[data['person_exist']==1])/len(data),3),\n",
    "    round(data['var'].mean(),3),\n",
    "    round(data['food'].mean(),3),\n",
    "    round(data['drink'].mean(),3),\n",
    "    round(data['menu'].mean(),3),\n",
    "    round(data['inside'].mean(),3),\n",
    "    round(data['outside'].mean(),3)\n",
    "    ]\n",
    "    return res\n",
    "\n",
    "def bus_result_std(data):\n",
    "    res = [\n",
    "    '-','-','-','-','-','-','-','-','-',\n",
    "    round(data['star_avg'].std(),3),\n",
    "    round(data['memory_score'].std(),3),\n",
    "    round(data['review_count'].std(),3),\n",
    "    round(data['photo_count'].std(),3),\n",
    "    round(data['categories_counts'].std(),3),\n",
    "    round(data['star_std'].std(),3),\n",
    "    round(data['contents_score_avg'].std(),3),\n",
    "    # round(data['useful_avg'].std(),3),\n",
    "    # round(data['funny_avg'].std(),3),\n",
    "    # round(data['cool_avg'].std(),3),\n",
    "    # round(data['person_count'].std(), 3),\n",
    "    round(data['beauty_score'].std(),3),\n",
    "    round(data['sharpness_measure'].std(),3),\n",
    "    round(data['average_hue'].std(), 3),\n",
    "    round(data['average_saturation'].std(),3),\n",
    "    round(data['average_value'].std(),3),\n",
    "    round(data['person_total_count_x'].std(),3),\n",
    "    '-',\n",
    "    round(data['var'].std(),3),\n",
    "    round(data['food'].std(),3),\n",
    "    round(data['drink'].std(),3),\n",
    "    round(data['menu'].std(),3),\n",
    "    round(data['inside'].std(),3),\n",
    "    round(data['outside'].std(),3)\n",
    "    ]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1747915660078,
     "user": {
      "displayName": "JUAN LI",
      "userId": "11406292856328700935"
     },
     "user_tz": -480
    },
    "id": "CVeWZu6iburw",
    "outputId": "cb8f4620-ecff-40be-a4d8-3946c72f8286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据保存成功\n"
     ]
    }
   ],
   "source": [
    "# business 均值和标准差的统计结果\n",
    "data = {\n",
    "    \"name\":[\"1\",\"1.5\",\"2\",\"2.5\",\"3\",\"3.5\",\"4\",\"4.5\",\"5\",\n",
    "            \"rating\",\"memory_score\",\"review_count\",\"photo_count\",\n",
    "    \"categories_counts\",\"star_std\",\"contents_score_avg\",\n",
    "    # \"useful_avg\",\"funny_avg\",\"cool_avg\",\"person_count\",\n",
    "    \"beauty_score\",\"sharpness_measure\",\"h\",\"s\",\"v\",\n",
    "    'person_total_count','person_exist','var',\n",
    "    'food','drink','menu','inside','outside'\n",
    "    ],\n",
    "    'All Busi mean': bus_result_mean(business_df),\n",
    "    'All Busi std': bus_result_std(business_df),\n",
    "    'All Res mean': bus_result_mean(business_res),\n",
    "    'All Res std': bus_result_std(business_res),\n",
    "    'Drink mean': bus_result_mean(business_drink),\n",
    "    'Drink std': bus_result_std(business_drink)\n",
    "}\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 显示DataFrame\n",
    "df.head()\n",
    "\n",
    "df.to_excel(\"data/output/study2_business_data_summary_yolo11.xlsx\",index=False)\n",
    "print(\"数据保存成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型前对数据进行标准化\n",
    "scaler = StandardScaler()\n",
    "business_df[['average_hue','average_saturation','average_value','sharpness_measure']] =  scaler.fit_transform(business_df[['average_hue','average_saturation','average_value','sharpness_measure']])\n",
    "business_res[['average_hue','average_saturation','average_value','sharpness_measure']] =  scaler.fit_transform(business_res[['average_hue','average_saturation','average_value','sharpness_measure']])\n",
    "business_drink[['average_hue','average_saturation','average_value','sharpness_measure']] =  scaler.fit_transform(business_drink[['average_hue','average_saturation','average_value','sharpness_measure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存数据用于做ivtest\n",
    "business_df['review_group'] = pd.qcut(business_df['review_count'], q=[0, 2/3, 1], labels=['low', 'high'])\n",
    "business_df.to_excel(\"data/output/study1_2_business_data.xlsx\",index=False)\n",
    "business_res['review_group'] = pd.qcut(business_res['review_count'], q=[0, 2/3, 1], labels=['low', 'high'])\n",
    "business_res.to_excel(\"data/output/study1_2_res_data.xlsx\",index=False) \n",
    "business_drink['review_group'] = pd.qcut(business_drink['review_count'], q=[0, 2/3, 1], labels=['low', 'high']) \n",
    "business_drink.to_excel(\"data/output/study1_2_drink_data.xlsx\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2sls_model_bus_res(data: pd.DataFrame):\n",
    "    data = data.copy() \n",
    "    data['memory_score'] = data['memory_score'] - data['memory_score'].mean()\n",
    "    data['review_group'] = pd.qcut(data['review_count'], q=[0, 2/3, 1], labels=['low', 'high'])\n",
    "    data['review_high'] = (data['review_group'] == 'high').astype(int)\n",
    "    data[\"memory_score_review_high\"]= data['memory_score']*data['review_high']\n",
    "    data[\"sharpness_measure_review_high\"]= data['sharpness_measure']*data['review_high']\n",
    "    data['log_photo_count'] = np.log(data['photo_count'])\n",
    "    w2sls_model = IV2SLS(\n",
    "    data[\"star_avg\"], \n",
    "    sm.add_constant(data[['categories_counts', \n",
    "    'average_hue', 'average_saturation', 'average_value', \n",
    "    'food', 'drink', 'menu', 'inside', \n",
    "    'var', 'person_exist', 'beauty_score', \n",
    "    'review_high'\n",
    "    ,'log_photo_count'\n",
    "    ]]), \n",
    "    data[[\"memory_score\",\"memory_score_review_high\"]], \n",
    "    data[[\"sharpness_measure\",\"sharpness_measure_review_high\",\"person_total_count_x\"]]\n",
    "    # weights=data[\"review_count\"]\n",
    "    ).fit(cov_type='robust')\n",
    "    return w2sls_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------1.all_business-----------------------------------------\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:               star_avg   R-squared:                      0.1121\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.1117\n",
      "No. Observations:               26769   F-statistic:                    3791.8\n",
      "Date:                Wed, Feb 18 2026   P-value (F-stat)                0.0000\n",
      "Time:                        15:47:07   Distribution:                 chi2(15)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                                    Parameter Estimates                                     \n",
      "============================================================================================\n",
      "                          Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        4.3465     0.1071     40.581     0.0000      4.1366      4.5564\n",
      "categories_counts            0.0006     0.0019     0.3133     0.7541     -0.0031      0.0042\n",
      "average_hue                 -0.0036     0.0057    -0.6264     0.5310     -0.0148      0.0076\n",
      "average_saturation          -0.0677     0.0057    -11.787     0.0000     -0.0789     -0.0564\n",
      "average_value               -0.1618     0.0092    -17.502     0.0000     -0.1799     -0.1437\n",
      "food                        -0.2147     0.0374    -5.7422     0.0000     -0.2880     -0.1414\n",
      "drink                       -0.1248     0.0590    -2.1162     0.0343     -0.2404     -0.0092\n",
      "menu                         0.2199     0.0744     2.9550     0.0031      0.0740      0.3657\n",
      "inside                      -0.0085     0.0246    -0.3462     0.7292     -0.0567      0.0397\n",
      "var                          0.1450     0.0319     4.5397     0.0000      0.0824      0.2076\n",
      "person_exist                 0.0360     0.0156     2.3180     0.0204      0.0056      0.0665\n",
      "beauty_score                -0.1785     0.0200    -8.9274     0.0000     -0.2176     -0.1393\n",
      "review_high                  0.3263     0.0180     18.147     0.0000      0.2911      0.3615\n",
      "log_photo_count              0.0884     0.0062     14.251     0.0000      0.0762      0.1005\n",
      "memory_score                -0.9414     0.4455    -2.1131     0.0346     -1.8146     -0.0682\n",
      "memory_score_review_high     5.0746     0.9897     5.1273     0.0000      3.1348      7.0144\n",
      "============================================================================================\n",
      "\n",
      "Endogenous: memory_score, memory_score_review_high\n",
      "Instruments: sharpness_measure, sharpness_measure_review_high, person_total_count_x\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n",
      "--------------------------------------------------2.restaurant--------------------------------------------------\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:               star_avg   R-squared:                      0.1235\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.1229\n",
      "No. Observations:               21150   F-statistic:                    3198.0\n",
      "Date:                Wed, Feb 18 2026   P-value (F-stat)                0.0000\n",
      "Time:                        15:47:07   Distribution:                 chi2(15)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                                    Parameter Estimates                                     \n",
      "============================================================================================\n",
      "                          Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        4.3373     0.1162     37.318     0.0000      4.1095      4.5651\n",
      "categories_counts            0.0046     0.0020     2.2999     0.0215      0.0007      0.0085\n",
      "average_hue                  0.0109     0.0060     1.8271     0.0677     -0.0008      0.0226\n",
      "average_saturation          -0.0740     0.0061    -12.177     0.0000     -0.0859     -0.0621\n",
      "average_value               -0.1246     0.0085    -14.575     0.0000     -0.1413     -0.1078\n",
      "food                        -0.1203     0.0389    -3.0926     0.0020     -0.1966     -0.0441\n",
      "drink                       -0.0534     0.0590    -0.9060     0.3649     -0.1691      0.0622\n",
      "menu                         0.2446     0.0773     3.1627     0.0016      0.0930      0.3961\n",
      "inside                       0.1142     0.0303     3.7652     0.0002      0.0547      0.1736\n",
      "var                          0.2257     0.0366     6.1696     0.0000      0.1540      0.2974\n",
      "person_exist                 0.0625     0.0171     3.6605     0.0003      0.0290      0.0960\n",
      "beauty_score                -0.2139     0.0222    -9.6503     0.0000     -0.2573     -0.1704\n",
      "review_high                  0.3240     0.0166     19.557     0.0000      0.2915      0.3564\n",
      "log_photo_count              0.0668     0.0066     10.105     0.0000      0.0538      0.0797\n",
      "memory_score                -0.7261     0.4047    -1.7941     0.0728     -1.5194      0.0671\n",
      "memory_score_review_high     3.9029     0.9540     4.0911     0.0000      2.0331      5.7727\n",
      "============================================================================================\n",
      "\n",
      "Endogenous: memory_score, memory_score_review_high\n",
      "Instruments: sharpness_measure, sharpness_measure_review_high, person_total_count_x\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "# order模型结果\n",
    "print('--------------------------------------------------1.all_business-----------------------------------------')\n",
    "order_df = w2sls_model_bus_res(business_df)\n",
    "print(order_df)\n",
    "print('--------------------------------------------------2.restaurant--------------------------------------------------')\n",
    "order_res = w2sls_model_bus_res(business_res)\n",
    "print(order_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存！\n",
      "           sample  memory_score  review_high                     status  \\\n",
      "0  All businesses      0.618850            0  Emerging (low visibility)   \n",
      "1  All businesses      0.620182            0  Emerging (low visibility)   \n",
      "2  All businesses      0.621515            0  Emerging (low visibility)   \n",
      "3  All businesses      0.622847            0  Emerging (low visibility)   \n",
      "4  All businesses      0.624180            0  Emerging (low visibility)   \n",
      "5  All businesses      0.625512            0  Emerging (low visibility)   \n",
      "6  All businesses      0.626844            0  Emerging (low visibility)   \n",
      "7  All businesses      0.628177            0  Emerging (low visibility)   \n",
      "8  All businesses      0.629509            0  Emerging (low visibility)   \n",
      "9  All businesses      0.630842            0  Emerging (low visibility)   \n",
      "\n",
      "       pred    ci_low   ci_high  \n",
      "0  3.707187  3.577470  3.836905  \n",
      "1  3.705933  3.577374  3.834492  \n",
      "2  3.704679  3.577277  3.832080  \n",
      "3  3.703424  3.577180  3.829669  \n",
      "4  3.702170  3.577083  3.827257  \n",
      "5  3.700916  3.576986  3.824845  \n",
      "6  3.699661  3.576889  3.822434  \n",
      "7  3.698407  3.576792  3.820022  \n",
      "8  3.697153  3.576694  3.817611  \n",
      "9  3.695898  3.576597  3.815200  \n"
     ]
    }
   ],
   "source": [
    "# 模型预测结果对比图数据加工\n",
    "from linearmodels.iv import IV2SLS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def fit_model_for_plot_2sls(df):\n",
    "    \"\"\"All Business / Restaurant 模型\"\"\"\n",
    "    df2 = df.copy()\n",
    "    mem_mean = df2['memory_score'].mean()\n",
    "    df2['memory_score'] = df2['memory_score'] - df2['memory_score'].mean()\n",
    "    df2['review_group'] = pd.qcut(df2['review_count'], q=[0, 2/3, 1], labels=['low', 'high'])\n",
    "    df2['review_high'] = (df2['review_group'] == 'high').astype(int)\n",
    "    df2['memory_score_review_high'] = df2['memory_score'] * df2['review_high']\n",
    "    df2['sharpness_measure_review_high'] = df2['sharpness_measure'] * df2['review_high']\n",
    "    df2['log_photo_count'] = np.log(df2['photo_count'])  #  加log变换\n",
    "\n",
    "    exog = sm.add_constant(df2[['categories_counts',\n",
    "                                'average_hue', 'average_saturation', 'average_value',\n",
    "                                'food', 'drink', 'menu', 'inside',\n",
    "                                'var', 'person_exist', 'beauty_score',\n",
    "                                'review_high', \n",
    "                                'log_photo_count']])  # 改为log_photo_count\n",
    "    endog = df2[['memory_score', 'memory_score_review_high']]\n",
    "    instruments = df2[['sharpness_measure', 'sharpness_measure_review_high', 'person_total_count_x']]\n",
    "\n",
    "    model = IV2SLS(df2['star_avg'], exog, endog, instruments).fit(cov_type='robust')\n",
    "    return model, df2, mem_mean \n",
    "\n",
    "\n",
    "def fit_model_for_plot_2sls_drink(df):\n",
    "    \"\"\"Drink 模型\"\"\"\n",
    "    df2 = df.copy()\n",
    "    mem_mean = df2['memory_score'].mean()\n",
    "    df2['memory_score'] = df2['memory_score'] - df2['memory_score'].mean()\n",
    "    df2['review_group'] = pd.qcut(df2['review_count'], q=[0, 2/3, 1], labels=['low', 'high'])\n",
    "    df2['review_high'] = (df2['review_group'] == 'high').astype(int)\n",
    "    df2['memory_score_review_high'] = df2['memory_score'] * df2['review_high']\n",
    "    df2['sharpness_measure_review_high'] = df2['sharpness_measure'] * df2['review_high']\n",
    "    df2['person_total_count_review_high'] = df2['person_total_count_x'] * df2['review_high']\n",
    "    df2['log_photo_count'] = np.log(df2['photo_count'])  #添加log变换\n",
    "\n",
    "    exog = sm.add_constant(df2[['categories_counts', 'sharpness_measure',\n",
    "                                'average_saturation', 'average_value',\n",
    "                                'food', 'drink', 'menu', 'inside',\n",
    "                                'var', 'person_exist', 'beauty_score',  \n",
    "                                'review_high',\n",
    "                                'log_photo_count']])  # 改为log_photo_count\n",
    "    endog = df2[['memory_score', 'memory_score_review_high']]\n",
    "    instruments = df2[['person_total_count_review_high', 'person_total_count_x', 'average_hue']]\n",
    "\n",
    "    model = IV2SLS(df2['star_avg'], exog, endog, instruments).fit(cov_type='robust')\n",
    "    return model, df2, mem_mean \n",
    "\n",
    "\n",
    "def make_pred_df_for_moderation(df, model, sample_label,mem_mean):\n",
    "    \"\"\"\n",
    "    All Business / Restaurant 预测函数\n",
    "    df: 对应样本的数据\n",
    "    model: fit 出来的回归对象\n",
    "    \"\"\"\n",
    "    dfc = df.copy()\n",
    "\n",
    "    # memory 范围：5% ~ 95% 分位\n",
    "    mem_min = dfc['memory_score'].quantile(0.05)\n",
    "    mem_max = dfc['memory_score'].quantile(0.95)\n",
    "    mem_grid = np.linspace(mem_min, mem_max, 200)\n",
    "\n",
    "    control_vars = [\n",
    "        'categories_counts',\n",
    "        'average_hue', 'average_saturation', 'average_value',\n",
    "        'food', 'drink', 'menu', 'inside',\n",
    "        'var', 'person_exist', 'beauty_score'\n",
    "    ]\n",
    "    control_means = dfc[control_vars].mean()\n",
    "\n",
    "    rows = []\n",
    "    for rh in [0, 1]:  # 0 = emerging, 1 = established\n",
    "        group_mean_rc = dfc.loc[dfc['review_high'] == rh, 'photo_count'].mean()\n",
    "        for m in mem_grid:\n",
    "            row = {}\n",
    "            for v in control_vars:\n",
    "                row[v] = control_means[v]\n",
    "            row['review_high'] = rh\n",
    "            row['log_photo_count'] = np.log(group_mean_rc)  # 改为log_photo_count\n",
    "            row['memory_score'] = m\n",
    "            row['memory_score_review_high'] = m * rh\n",
    "            row['sample'] = sample_label\n",
    "            rows.append(row)\n",
    "\n",
    "    newdata = pd.DataFrame(rows)\n",
    "\n",
    "    # 用模型系数计算预测值和 CI\n",
    "    param_names = model.params.index.tolist()\n",
    "    newdata = newdata.assign(const=1.0)\n",
    "    for name in param_names:\n",
    "        if name not in newdata.columns:\n",
    "            newdata[name] = 0.0\n",
    "\n",
    "    X = newdata[param_names].values\n",
    "    beta = model.params.values\n",
    "    cov = model.cov.loc[param_names, param_names].values\n",
    "\n",
    "    y_hat = X @ beta\n",
    "    var_hat = np.einsum('ij,jk,ik->i', X, cov, X)\n",
    "    se_hat = np.sqrt(np.maximum(var_hat, 0))\n",
    "\n",
    "    newdata['pred'] = y_hat\n",
    "    newdata['ci_low'] = y_hat - 1.96 * se_hat\n",
    "    newdata['ci_high'] = y_hat + 1.96 * se_hat\n",
    "\n",
    "    newdata['memory_score'] = np.tile(mem_grid, 2)+mem_mean\n",
    "    newdata['review_high'] = np.repeat([0, 1], len(mem_grid))\n",
    "    newdata['status'] = np.where(newdata['review_high'] == 1,\n",
    "                                 'Established (high visibility)',\n",
    "                                 'Emerging (low visibility)')\n",
    "    return newdata\n",
    "\n",
    "\n",
    "def make_pred_df_for_moderation_drink(df, model, sample_label,mem_mean):\n",
    "    \"\"\"\n",
    "    Drink 专用预测函数（control_vars 不同）\n",
    "    \"\"\"\n",
    "    dfc = df.copy()\n",
    "\n",
    "    mem_min = dfc['memory_score'].quantile(0.05)\n",
    "    mem_max = dfc['memory_score'].quantile(0.95)\n",
    "    mem_grid = np.linspace(mem_min, mem_max, 200)\n",
    "\n",
    "    # Drink模型的control_vars不同\n",
    "    control_vars = [\n",
    "        'categories_counts', \n",
    "        'sharpness_measure',  # Drink用sharpness_measure替代average_hue\n",
    "        'average_saturation', 'average_value',\n",
    "        'food', 'drink', 'menu', 'inside',\n",
    "        'var', 'person_exist', 'beauty_score'\n",
    "    ]\n",
    "    control_means = dfc[control_vars].mean()\n",
    "\n",
    "    rows = []\n",
    "    for rh in [0, 1]:\n",
    "        group_mean_rc = dfc.loc[dfc['review_high'] == rh, 'photo_count'].mean()\n",
    "        for m in mem_grid:\n",
    "            row = {}\n",
    "            for v in control_vars:\n",
    "                row[v] = control_means[v]\n",
    "            row['review_high'] = rh\n",
    "            row['log_photo_count'] = np.log(group_mean_rc)  # 改为log_photo_count\n",
    "            row['memory_score'] = m\n",
    "            row['memory_score_review_high'] = m * rh\n",
    "            row['sample'] = sample_label\n",
    "            rows.append(row)\n",
    "\n",
    "    newdata = pd.DataFrame(rows)\n",
    "\n",
    "    param_names = model.params.index.tolist()\n",
    "    newdata = newdata.assign(const=1.0)\n",
    "    for name in param_names:\n",
    "        if name not in newdata.columns:\n",
    "            newdata[name] = 0.0\n",
    "\n",
    "    X = newdata[param_names].values\n",
    "    beta = model.params.values\n",
    "    cov = model.cov.loc[param_names, param_names].values\n",
    "\n",
    "    y_hat = X @ beta\n",
    "    var_hat = np.einsum('ij,jk,ik->i', X, cov, X)\n",
    "    se_hat = np.sqrt(np.maximum(var_hat, 0))\n",
    "\n",
    "    newdata['pred'] = y_hat\n",
    "    newdata['ci_low'] = y_hat - 1.96 * se_hat\n",
    "    newdata['ci_high'] = y_hat + 1.96 * se_hat\n",
    "\n",
    "    newdata['memory_score'] = np.tile(mem_grid, 2)+mem_mean\n",
    "    newdata['review_high'] = np.repeat([0, 1], len(mem_grid))\n",
    "    newdata['status'] = np.where(newdata['review_high'] == 1,\n",
    "                                 'Established (high visibility)',\n",
    "                                 'Emerging (low visibility)')\n",
    "    return newdata\n",
    "\n",
    "\n",
    "def plot_moderation(pred_df, title):\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    for rh, label in [(0, 'Emerging (low visibility)'),\n",
    "                      (1, 'Established (high visibility)')]:\n",
    "        tmp = pred_df[pred_df['review_high'] == rh].sort_values('memory_score')\n",
    "\n",
    "        x = tmp['memory_score'].astype(float).values\n",
    "        y = tmp['pred'].astype(float).values\n",
    "        y1 = tmp['ci_low'].astype(float).values\n",
    "        y2 = tmp['ci_high'].astype(float).values\n",
    "\n",
    "        ax.plot(x, y, label=label)\n",
    "        ax.fill_between(x, y1, y2, alpha=0.2)\n",
    "\n",
    "    ax.set_xlabel('Image memorability (business level)')\n",
    "    ax.set_ylabel('Predicted average rating')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(title='Business status')\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "# ============== 调用代码 ==============\n",
    "# 1）All businesses\n",
    "model_bus, bus_clean, mem_mean = fit_model_for_plot_2sls(business_df)\n",
    "bus_pred = make_pred_df_for_moderation(bus_clean, model_bus, \"All businesses\", mem_mean)\n",
    "\n",
    "# 2）Restaurants\n",
    "model_res, res_clean, mem_mean = fit_model_for_plot_2sls(business_res)\n",
    "res_pred = make_pred_df_for_moderation(res_clean, model_res, \"Restaurants\", mem_mean)\n",
    "\n",
    "# 3）Drinks-使用专用函数\n",
    "model_drink, drink_clean, mem_mean = fit_model_for_plot_2sls_drink(business_drink)\n",
    "drink_pred = make_pred_df_for_moderation_drink(drink_clean, model_drink, \"Drinks\", mem_mean)\n",
    "\n",
    "# ============== 保存数据为 CSV ==============\n",
    "all_pred = pd.concat([bus_pred, res_pred, drink_pred], ignore_index=True)\n",
    "all_pred.to_csv(\"data/output/plot_data_moderation_all.csv\", index=False)\n",
    "\n",
    "print(\"数据已保存！\")\n",
    "print(all_pred[['sample', 'memory_score', 'review_high', 'status', 'pred', 'ci_low', 'ci_high']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------3.drink--------------------------------------------------\n",
      "                          IV-2SLS Estimation Summary                          \n",
      "==============================================================================\n",
      "Dep. Variable:               star_avg   R-squared:                      0.1294\n",
      "Estimator:                    IV-2SLS   Adj. R-squared:                 0.1281\n",
      "No. Observations:                9751   F-statistic:                    1229.0\n",
      "Date:                Wed, Feb 18 2026   P-value (F-stat)                0.0000\n",
      "Time:                        15:47:07   Distribution:                 chi2(15)\n",
      "Cov. Estimator:                robust                                         \n",
      "                                                                              \n",
      "                                    Parameter Estimates                                     \n",
      "============================================================================================\n",
      "                          Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        3.9645     0.1775     22.338     0.0000      3.6166      4.3123\n",
      "categories_counts            0.0317     0.0030     10.504     0.0000      0.0258      0.0376\n",
      "sharpness_measure            0.0846     0.0089     9.5435     0.0000      0.0672      0.1019\n",
      "average_saturation          -0.0651     0.0086    -7.6087     0.0000     -0.0819     -0.0483\n",
      "average_value               -0.1351     0.0157    -8.6013     0.0000     -0.1659     -0.1043\n",
      "food                         0.0286     0.0631     0.4528     0.6507     -0.0951      0.1522\n",
      "drink                        0.0671     0.0954     0.7040     0.4815     -0.1198      0.2541\n",
      "menu                         0.0773     0.1331     0.5806     0.5615     -0.1835      0.3380\n",
      "inside                       0.1034     0.0410     2.5193     0.0118      0.0230      0.1838\n",
      "var                          0.1685     0.0466     3.6137     0.0003      0.0771      0.2599\n",
      "person_exist                 0.2286     0.0246     9.2981     0.0000      0.1804      0.2767\n",
      "beauty_score                -0.1730     0.0339    -5.1079     0.0000     -0.2394     -0.1066\n",
      "review_high                  0.0650     0.0183     3.5461     0.0004      0.0291      0.1009\n",
      "log_photo_count              0.0650     0.0088     7.3795     0.0000      0.0477      0.0823\n",
      "memory_score                -0.1935     0.5864    -0.3299     0.7415     -1.3429      0.9560\n",
      "memory_score_review_high     2.1158     0.4451     4.7536     0.0000      1.2434      2.9882\n",
      "============================================================================================\n",
      "\n",
      "Endogenous: memory_score, memory_score_review_high\n",
      "Instruments: person_total_count_review_high, person_total_count_x, average_hue\n",
      "Robust Covariance (Heteroskedastic)\n",
      "Debiased: False\n"
     ]
    }
   ],
   "source": [
    "def w2sls_model_drink(data: pd.DataFrame):\n",
    "    data = data.copy() \n",
    "    data['memory_score'] = data['memory_score'] - data['memory_score'].mean()\n",
    "    data['review_group'] = pd.qcut(data['review_count'], q=[0, 2/3, 1], labels=['low', 'high'])\n",
    "    data['review_high'] = (data['review_group'] == 'high').astype(int)\n",
    "    data[\"memory_score_review_high\"]= data['memory_score']*data['review_high']\n",
    "    data[\"sharpness_measure_review_high\"]= data['sharpness_measure']*data['review_high']\n",
    "    data[\"person_total_count_review_high\"]= data['person_total_count_x']*data['review_high']\n",
    "    data['log_photo_count'] = np.log(data['photo_count'])\n",
    "    w2sls_model = IV2SLS(\n",
    "    data[\"star_avg\"],\n",
    "    sm.add_constant(data[['categories_counts', \"sharpness_measure\",\n",
    "    'average_saturation', 'average_value', \n",
    "    'food', 'drink', 'menu', 'inside', \n",
    "    'var', 'person_exist', 'beauty_score', \n",
    "    'review_high'\n",
    "    ,'log_photo_count']]), \n",
    "    data[[\"memory_score\",\"memory_score_review_high\"]], \n",
    "    data[[\"person_total_count_review_high\",\"person_total_count_x\",'average_hue']]\n",
    "    # weights=data[\"review_count\"]\n",
    "    ).fit(cov_type='robust')\n",
    "    return w2sls_model\n",
    "\n",
    "\n",
    "print('--------------------------------------------------3.drink--------------------------------------------------')\n",
    "order_drink = w2sls_model_drink(business_drink)\n",
    "print(order_drink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split_new(df):\n",
    "    df['review_group'] = pd.qcut(df['review_count'], q=[0, 2/3, 1], labels=['low', 'high'])\n",
    "    df_high = df[df['review_group']=='high']\n",
    "    df_low = df[df['review_group']=='low']\n",
    "    return df_high,df_low\n",
    "\n",
    "business_df_high,business_df_low = data_split_new(business_df)\n",
    "business_res_high,business_res_low = data_split_new(business_res)\n",
    "business_drink_high,business_drink_low = data_split_new(business_drink)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------高低评论数量 情感的倾向均值-------------------------\n",
      "sentiment analysis\n",
      "--------------------------------------------------1.all_business--------------------------------------------------\n",
      "high 0.702 low 0.536\n",
      "memory score\n",
      "high 0.736 low 0.771\n",
      "ANOVA结果: F = 2321.246, p = 0.0000\n",
      "ANOVA结果: F = 1164.557, p = 0.0000\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj lower   upper  reject\n",
      "--------------------------------------------------\n",
      "  High    Low  -0.1662   0.0 -0.173 -0.1595   True\n",
      "--------------------------------------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "=================================================\n",
      "group1 group2 meandiff p-adj lower  upper  reject\n",
      "-------------------------------------------------\n",
      "  High    Low   0.0352   0.0 0.0332 0.0372   True\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------2.restaurant--------------------------------------------------\n",
      "high 0.707 low 0.537\n",
      "memory score\n",
      "high 0.734 low 0.765\n",
      "ANOVA结果: F = 2097.981, p = 0.0000\n",
      "ANOVA结果: F = 771.737, p = 0.0000\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------\n",
      "  High    Low  -0.1701   0.0 -0.1774 -0.1628   True\n",
      "---------------------------------------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "=================================================\n",
      "group1 group2 meandiff p-adj lower  upper  reject\n",
      "-------------------------------------------------\n",
      "  High    Low   0.0311   0.0 0.0289 0.0333   True\n",
      "-------------------------------------------------\n",
      "--------------------------------------------------3.drink--------------------------------------------------\n",
      "high 0.717 low 0.595\n",
      "memory score\n",
      "high 0.727 low 0.754\n",
      "ANOVA结果: F = 528.615, p = 0.0000\n",
      "ANOVA结果: F = 233.107, p = 0.0000\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "===================================================\n",
      "group1 group2 meandiff p-adj  lower   upper  reject\n",
      "---------------------------------------------------\n",
      "  High    Low  -0.1218   0.0 -0.1321 -0.1114   True\n",
      "---------------------------------------------------\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "=================================================\n",
      "group1 group2 meandiff p-adj lower  upper  reject\n",
      "-------------------------------------------------\n",
      "  High    Low   0.0271   0.0 0.0236 0.0306   True\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------高低评论数量 情感的倾向均值-------------------------\")\n",
    "# business\n",
    "def sentiment_analysis(business_df_high,business_df_low,file_name):\n",
    "    from scipy import stats\n",
    "    print(\"high\",round(business_df_high['contents_score_avg'].mean(),3),\n",
    "    \"low\",round(business_df_low['contents_score_avg'].mean(),3))\n",
    "    print(\"memory score\")\n",
    "    print(\"high\",round(business_df_high['memory_score'].mean(),3),\n",
    "    \"low\",round(business_df_low['memory_score'].mean(),3))\n",
    "    # ANOVA\n",
    "    t_stat, p_val = stats.f_oneway(business_df_high['contents_score_avg'],\n",
    "                                    business_df_low['contents_score_avg'])\n",
    "    print(f\"ANOVA结果: F = {t_stat:.3f}, p = {p_val:.4f}\")\n",
    "    t_stat, p_val = stats.f_oneway(business_df_high['memory_score'],\n",
    "                                    business_df_low['memory_score'])\n",
    "    print(f\"ANOVA结果: F = {t_stat:.3f}, p = {p_val:.4f}\")\n",
    "    # =====ANOVA结果显著，可以做事后检验（Tukey HSD）=====\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "    # 拼接成一个DataFrame\n",
    "    df = pd.DataFrame({'sentiment_score': pd.concat([business_df_high['contents_score_avg'], \n",
    "                                        business_df_low['contents_score_avg']]),\n",
    "        \"group\": ([\"High\"]*len(business_df_high) +\n",
    "                [\"Low\"]*len(business_df_low))\n",
    "    })\n",
    "\n",
    "    tukey = pairwise_tukeyhsd(endog=df['sentiment_score'], groups=df[\"group\"], alpha=0.05)\n",
    "    print(tukey)\n",
    "\n",
    "    df.to_excel(\"data/output/{}.xlsx\".format(file_name),index=False)\n",
    "\n",
    "    # 拼接成一个DataFrame\n",
    "    df = pd.DataFrame({'sentiment_score': pd.concat([business_df_high['memory_score'], \n",
    "                                        business_df_low['memory_score']]),\n",
    "        \"group\": ([\"High\"]*len(business_df_high) +\n",
    "                [\"Low\"]*len(business_df_low))\n",
    "    })\n",
    "    tukey = pairwise_tukeyhsd(endog=df['sentiment_score'], groups=df[\"group\"], alpha=0.05)\n",
    "    print(tukey)\n",
    "\n",
    "\n",
    "print(\"sentiment analysis\")\n",
    "print(\"--------------------------------------------------1.all_business--------------------------------------------------\")\n",
    "sentiment_analysis(business_df_high,business_df_low,\"all_business_sentiment\")\n",
    "print(\"--------------------------------------------------2.restaurant--------------------------------------------------\")\n",
    "sentiment_analysis(business_res_high,business_res_low,\"restaurant_sentiment\")\n",
    "print(\"--------------------------------------------------3.drink--------------------------------------------------\")\n",
    "sentiment_analysis(business_drink_high,business_drink_low,\"drink_sentiment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
